{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project03_NBLR.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nVZXDuhNKFZQ",
        "hzTGOCPWzIeV",
        "5KC2y7ZKzWwH",
        "o2ek-0b7zp9r",
        "fig_PpdOzBJN",
        "3Mj-Yf4T0NWN",
        "VfK4RxMfKRqP",
        "_NTfIpdbllvF",
        "JtGbFXmDxjkW",
        "3igcp1czM3oY"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmCu1DUXbkVq",
        "outputId": "e2d3dd6a-3490-4b2d-f4d9-b29bb19e9e2f"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdQ0HE3DT-Z3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords as STOPWORDS\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "stopWords = set(STOPWORDS.words('turkish'))\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjSwujdtK5Gx"
      },
      "source": [
        "def preprocess(docs):\n",
        "    result = []\n",
        "    for d in docs:\n",
        "        a = re.sub(r'[\\'’\\\"”][\\w]+ ', \" \" ,d)\n",
        "        for stopword in stopWords:\n",
        "            a = a.replace(\" \"+ stopword + \" \", \" \")\n",
        "        a = re.sub(r'[“’‘\\'\\\"”…]', \"\", a)\n",
        "        a = re.sub(r'\\d+', \"\", a)\n",
        "        a = a.replace(\"  \", \" \")\n",
        "        result.append(a.lower())\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7flkJzHoTDmT"
      },
      "source": [
        "def read_data(path):\n",
        "    data = pd.read_csv(path)\n",
        "    return data\n",
        "\n",
        "path = \"/content/drive/MyDrive/CS 445 Project 3/dataset/train.csv\"\n",
        "data = read_data(path)\n",
        "\n",
        "path = \"/content/drive/MyDrive/CS 445 Project 3/dataset/test.csv\"\n",
        "test_data = read_data(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otxsxDXzsxjU"
      },
      "source": [
        "data_text = data[\"text\"]\n",
        "data_label = data[\"label\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NjC_u2fG2Tj"
      },
      "source": [
        "test_data_text = test_data[\"text\"]\r\n",
        "test_data_label = test_data[\"label\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "lvtFm49FLBG_",
        "outputId": "673bba71-a2e4-4cf3-ab9e-f4a33455c1e5"
      },
      "source": [
        "data_text[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Beşiktaş'ın eski teknik direktörü Slaven Bilic, Türkiye-Hırvatistan maçında yorumculuk yapmak üzere Lig TV ile anlaştı.\\nEURO 2016'nın yayıncı kuruluşlarından biri olan Lig TV, Türkiye'nin D Grubu'nda Hırvatistan ile oynayacağı ilk maç için Slaven Bilic ile anlaşıldığını duyurdu.\\nBeşiktaş'ın eski teknik direktörü Slaven Bilic, 12 Haziran Pazar günü TSİ 16:00'da başlayacak mücadelede yorumcu olacak.\\nLig TV, Slaven Bilic'in yanı sıra A Milli Takım'ın efsane kalecilerinden Rüştü Reçber'in de bu karşılaşmanın yorumcularından biri olacağını açıkladı.\\nEURO 2008'de Hırvatistan'ın teknik direktörü olan Slaven Bilic, çeyrek finalde Türkiye'ye rakip olmuş ve 120 dakikası 1-1 biten maçta A Milli Takımımıza penaltılarda elenmişti.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA2tdmjSLBep"
      },
      "source": [
        "data_text_processed = preprocess(data_text)\n",
        "test_data_text_processed = preprocess(test_data_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "XciHuvtELB3G",
        "outputId": "d1d7004e-a8c8-4aaf-cccf-2f0be921072f"
      },
      "source": [
        "data_text_processed[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'beşiktaş eski teknik direktörü slaven bilic, türkiye-hırvatistan maçında yorumculuk yapmak üzere lig tv anlaştı.\\neuro yayıncı kuruluşlarından olan lig tv, türkiye d grubu hırvatistan oynayacağı ilk maç slaven bilic anlaşıldığını duyurdu.\\nbeşiktaş eski teknik direktörü slaven bilic, haziran pazar günü tsi̇ : başlayacak mücadelede yorumcu olacak.\\nlig tv, slaven bilic yanı sıra a milli takım efsane kalecilerinden rüştü reçber karşılaşmanın yorumcularından olacağını açıkladı.\\neuro hırvatistan teknik direktörü olan slaven bilic, çeyrek finalde türkiye rakip olmuş dakikası - biten maçta a milli takımımıza penaltılarda elenmişti.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG_MzEJOi5Oq"
      },
      "source": [
        "class_mapping = {\n",
        "    \"turkiye\": 0,\n",
        "    \"dunya\": 1,\n",
        "    \"spor\": 2,\n",
        "    \"video\": 3,\n",
        "    \"yazarlar\": 4,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReUOtMV4jK6U"
      },
      "source": [
        "counts = {\n",
        "    \"turkiye\": 0,\n",
        "    \"dunya\": 0,\n",
        "    \"spor\": 0,\n",
        "    \"video\": 0,\n",
        "    \"yazarlar\": 0, \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgF-7FPOjTxi",
        "outputId": "c22249b5-1835-4fe1-f7df-ba9db9b3f63f"
      },
      "source": [
        "for label in data_label:\n",
        "    counts[label] += 1\n",
        "\n",
        "print(counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'turkiye': 1630, 'dunya': 1606, 'spor': 1583, 'video': 1582, 'yazarlar': 1599}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ-47nBSkMhy"
      },
      "source": [
        "counts = {\n",
        "    \"turkiye\": 0,\n",
        "    \"dunya\": 0,\n",
        "    \"spor\": 0,\n",
        "    \"video\": 0,\n",
        "    \"yazarlar\": 0, \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp0ScAvBkLBi",
        "outputId": "c3d4863f-4487-483e-d7f1-3f8ca8fea037"
      },
      "source": [
        "for label in test_data_label:\n",
        "    counts[label] += 1\n",
        "\n",
        "print(counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'turkiye': 421, 'dunya': 395, 'spor': 384, 'video': 408, 'yazarlar': 392}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkvxgsg432oU"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(data_text, data_label, test_size=0.1, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY7KoOQALQee"
      },
      "source": [
        "vectorizerList = [\"TF\", \"TF-IDF\"]\n",
        "includeStopWordsList = [ \"yes\", \"no\" ]\n",
        "\n",
        "def loopAllForNB(data_text, data_label, test_data_text, test_data_label, data_type):\n",
        "\n",
        "    outFile = open(\"/content/drive/MyDrive/CS 445 Project 3/Naive Bayes_\" + data_type + \".txt\", \"w\")\n",
        "\n",
        "    test_results = {}\n",
        "\n",
        "    for includeStopWords in includeStopWordsList:\n",
        "        for vectorizerType in vectorizerList:\n",
        "            if includeStopWords == \"yes\" and vectorizerType == \"TF\":\n",
        "                vectorizer = CountVectorizer()\n",
        "            \n",
        "            elif includeStopWords == \"yes\" and vectorizerType == \"TF-IDF\":\n",
        "                vectorizer = TfidfVectorizer()\n",
        "            \n",
        "            elif includeStopWords == \"no\" and vectorizerType == \"TF\":\n",
        "                vectorizer = CountVectorizer(stop_words=stopWords)\n",
        "            \n",
        "            elif includeStopWords == \"no\" and vectorizerType == \"TF-IDF\":\n",
        "                vectorizer = TfidfVectorizer(stop_words=stopWords)\n",
        "\n",
        "            else:\n",
        "                print(\"What are doing here???\")\n",
        "                return\n",
        "\n",
        "            X_train, X_valid, y_train, y_valid = train_test_split(data_text, data_label, test_size=0.1, random_state=1)\n",
        "\n",
        "            title = \"Vectorizer Type: \" + vectorizerType + \"\\tInclude Stopwords: \" + includeStopWords + \"\\tData Type: \" + data_type\n",
        "            \n",
        "            outFile.write(\"*** Start For \" + title + \" ***\\n\")\n",
        "\n",
        "            model = make_pipeline(vectorizer, MultinomialNB())\n",
        "\n",
        "            print(\"Fitting data:\", title)\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Predict the Validation Data\n",
        "            predictions = model.predict(X_valid)\n",
        "\n",
        "            # Accuracy of the Naive Bayes for validation\n",
        "            accuracy_validation_nb = accuracy_score(y_valid, predictions)\n",
        "\n",
        "            print(\"Classification Report for Naive Bayesian (Validation) -->\", title)\n",
        "            print(classification_report(y_valid, predictions))\n",
        "            \n",
        "            outFile.write(\"Classification Report for Naive Bayesian (Validation) --> \" + title + \"\\n\")\n",
        "            outFile.write(classification_report(y_valid, predictions))\n",
        "            outFile.write(\"\\n\\n\\n\")\n",
        "\n",
        "            # Accuracy of the Naive Bayes for test\n",
        "            model.fit(data_text, data_label)\n",
        "\n",
        "            predictions = model.predict(test_data_text)\n",
        "\n",
        "            accuracy_test_nb = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "            print(\"Classification Report for Naive Bayesian (Test) -->\", title)\n",
        "            print(classification_report(test_data_label, predictions))\n",
        "\n",
        "            outFile.write(\"Classification Report for Naive Bayesian (Test) --> \" + title + \"\\n\")\n",
        "            outFile.write(classification_report(test_data_label, predictions))\n",
        "            outFile.write(\"\\n\\n\\n\")\n",
        "\n",
        "            # Accuracy with Fine-Tuning (GridSearchCV)\n",
        "            print(\"\\n*** GridSearchCV Starts ***\\n\")\n",
        "            vec_x = vectorizer.fit_transform(data_text)\n",
        "\n",
        "            grid = GridSearchCV(MultinomialNB(), param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001]}, scoring=\"accuracy\")\n",
        "            grid.fit(vec_x, data_label)\n",
        "\n",
        "            print(\"\\t\\tBest estimators:\", grid.best_estimator_)\n",
        "            print(\"\\t\\tBest params:\", grid.best_params_)\n",
        "            print(\"\\t\\tValidation Score (Fine-Tuning):\", grid.best_score_)\n",
        "\n",
        "            # Fine-Tuned NaiveBayes\n",
        "            best_alpha = grid.best_params_[\"alpha\"]\n",
        "            print(\"\\n*** Test Data Starts with Fine-Tune ***\\n\")\n",
        "            model = make_pipeline(vectorizer, MultinomialNB(alpha=best_alpha))\n",
        "\n",
        "            model.fit(data_text, data_label)\n",
        "            predictions = model.predict(test_data_text)\n",
        "\n",
        "            accuracy_test_nb_fine_tuned = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "            print(\"Classification Report for Naive Bayesian Fine-Tuned (Test) -->\", title)\n",
        "            print(classification_report(test_data_label, predictions))\n",
        "\n",
        "            outFile.write(\"Classification Report for Naive Bayesian Fine-Tuned (Test) --> \" + title + \"\\n\")\n",
        "            outFile.write(classification_report(test_data_label, predictions))\n",
        "            outFile.write(\"\\n\\n\")\n",
        "\n",
        "\n",
        "            print(\"\\n\\n*** Accuracy Results ***\")\n",
        "            print(\"Accuracy Score for validation data:\", accuracy_validation_nb)\n",
        "            print(\"Accuracy Score for test data:\", accuracy_test_nb)\n",
        "            print(\"Accuracy Score for test data (fine-tuned):\", accuracy_test_nb_fine_tuned, \"\\n\\n\\n\")\n",
        "\n",
        "            test_results[title] = accuracy_test_nb\n",
        "            test_results[title+\"(fineTuned)\"] = accuracy_test_nb_fine_tuned\n",
        "\n",
        "            outFile.write(\"\\n\\n*** Accuracy Results ***\\n\")\n",
        "            outFile.write(\"Accuracy Score for validation data: \" + str(accuracy_validation_nb) + \"\\n\" )\n",
        "            outFile.write(\"Accuracy Score for test data: \" + str(accuracy_test_nb) + \"\\n\" )\n",
        "            outFile.write(\"Accuracy Score for test data (fine-tuned): \" + str(accuracy_test_nb_fine_tuned) + \"\\n\\n\\n\" )\n",
        "            \n",
        "            outFile.write(\"*** End For \" + title + \" ***\\n\\n\\n\")\n",
        "\n",
        "    print(\"*** Final Results ***\")\n",
        "    outFile.write(\"*** Final Results ***\\n\")\n",
        "    for key, value in test_results.items():\n",
        "        print(key, \" -->\\t\", value)\n",
        "        outFile.write( key + \" :\\t\" + str(value) + \"\\n\" )\n",
        "\n",
        "    outFile.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9oxRB59RlH2",
        "outputId": "c08dd8f6-4dbb-4f0c-b87c-ba9ef343b89d"
      },
      "source": [
        "loopAllForNB(data_text, data_label, test_data_text, test_data_label, \"normal\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting data: Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal\n",
            "Classification Report for Naive Bayesian (Validation) --> Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.86      0.84       154\n",
            "        spor       0.89      0.97      0.93       151\n",
            "     turkiye       0.61      0.83      0.71       168\n",
            "       video       0.93      0.24      0.38       156\n",
            "    yazarlar       0.76      0.91      0.83       171\n",
            "\n",
            "    accuracy                           0.76       800\n",
            "   macro avg       0.80      0.76      0.74       800\n",
            "weighted avg       0.80      0.76      0.73       800\n",
            "\n",
            "Classification Report for Naive Bayesian (Test) --> Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.80      0.85      0.82       395\n",
            "        spor       0.89      0.95      0.92       384\n",
            "     turkiye       0.58      0.77      0.66       421\n",
            "       video       0.92      0.20      0.32       408\n",
            "    yazarlar       0.72      0.96      0.83       392\n",
            "\n",
            "    accuracy                           0.74      2000\n",
            "   macro avg       0.78      0.75      0.71      2000\n",
            "weighted avg       0.78      0.74      0.71      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
            "\t\tBest params: {'alpha': 0.1}\n",
            "\t\tValidation Score (Fine-Tuning): 0.786125\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Naive Bayesian Fine-Tuned (Test) --> Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.81      0.85      0.83       395\n",
            "        spor       0.91      0.95      0.93       384\n",
            "     turkiye       0.67      0.65      0.66       421\n",
            "       video       0.71      0.52      0.60       408\n",
            "    yazarlar       0.78      0.96      0.86       392\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.78      0.79      0.78      2000\n",
            "weighted avg       0.77      0.78      0.77      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.76375\n",
            "Accuracy Score for test data: 0.742\n",
            "Accuracy Score for test data (fine-tuned): 0.781 \n",
            "\n",
            "\n",
            "\n",
            "Fitting data: Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal\n",
            "Classification Report for Naive Bayesian (Validation) --> Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.84      0.73      0.78       154\n",
            "        spor       0.88      0.95      0.91       151\n",
            "     turkiye       0.65      0.73      0.69       168\n",
            "       video       0.95      0.27      0.42       156\n",
            "    yazarlar       0.60      0.95      0.73       171\n",
            "\n",
            "    accuracy                           0.73       800\n",
            "   macro avg       0.78      0.72      0.71       800\n",
            "weighted avg       0.78      0.73      0.71       800\n",
            "\n",
            "Classification Report for Naive Bayesian (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.80      0.76      0.78       395\n",
            "        spor       0.89      0.94      0.92       384\n",
            "     turkiye       0.59      0.67      0.63       421\n",
            "       video       0.95      0.20      0.34       408\n",
            "    yazarlar       0.58      0.98      0.73       392\n",
            "\n",
            "    accuracy                           0.71      2000\n",
            "   macro avg       0.77      0.71      0.68      2000\n",
            "weighted avg       0.76      0.71      0.67      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "\t\tBest params: {'alpha': 0.01}\n",
            "\t\tValidation Score (Fine-Tuning): 0.789125\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Naive Bayesian Fine-Tuned (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.84      0.83       395\n",
            "        spor       0.91      0.95      0.93       384\n",
            "     turkiye       0.64      0.67      0.66       421\n",
            "       video       0.76      0.47      0.58       408\n",
            "    yazarlar       0.76      0.96      0.85       392\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.78      0.78      0.77      2000\n",
            "weighted avg       0.78      0.78      0.77      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.7275\n",
            "Accuracy Score for test data: 0.7055\n",
            "Accuracy Score for test data (fine-tuned): 0.7765 \n",
            "\n",
            "\n",
            "\n",
            "Fitting data: Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal\n",
            "Classification Report for Naive Bayesian (Validation) --> Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.84      0.84       154\n",
            "        spor       0.90      0.97      0.93       151\n",
            "     turkiye       0.61      0.84      0.71       168\n",
            "       video       0.88      0.24      0.37       156\n",
            "    yazarlar       0.76      0.91      0.83       171\n",
            "\n",
            "    accuracy                           0.76       800\n",
            "   macro avg       0.79      0.76      0.74       800\n",
            "weighted avg       0.79      0.76      0.74       800\n",
            "\n",
            "Classification Report for Naive Bayesian (Test) --> Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.79      0.86      0.82       395\n",
            "        spor       0.89      0.96      0.92       384\n",
            "     turkiye       0.58      0.77      0.66       421\n",
            "       video       0.91      0.21      0.34       408\n",
            "    yazarlar       0.75      0.95      0.84       392\n",
            "\n",
            "    accuracy                           0.75      2000\n",
            "   macro avg       0.78      0.75      0.72      2000\n",
            "weighted avg       0.78      0.75      0.71      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
            "\t\tBest params: {'alpha': 0.1}\n",
            "\t\tValidation Score (Fine-Tuning): 0.7838749999999999\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Naive Bayesian Fine-Tuned (Test) --> Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.81      0.84      0.83       395\n",
            "        spor       0.91      0.95      0.93       384\n",
            "     turkiye       0.67      0.66      0.66       421\n",
            "       video       0.70      0.51      0.59       408\n",
            "    yazarlar       0.79      0.95      0.86       392\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.78      0.78      0.78      2000\n",
            "weighted avg       0.77      0.78      0.77      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.76375\n",
            "Accuracy Score for test data: 0.7465\n",
            "Accuracy Score for test data (fine-tuned): 0.7795 \n",
            "\n",
            "\n",
            "\n",
            "Fitting data: Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal\n",
            "Classification Report for Naive Bayesian (Validation) --> Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.81      0.77      0.79       154\n",
            "        spor       0.89      0.97      0.93       151\n",
            "     turkiye       0.65      0.74      0.69       168\n",
            "       video       0.96      0.29      0.44       156\n",
            "    yazarlar       0.63      0.93      0.75       171\n",
            "\n",
            "    accuracy                           0.74       800\n",
            "   macro avg       0.79      0.74      0.72       800\n",
            "weighted avg       0.78      0.74      0.72       800\n",
            "\n",
            "Classification Report for Naive Bayesian (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.80      0.78      0.79       395\n",
            "        spor       0.90      0.95      0.92       384\n",
            "     turkiye       0.60      0.69      0.64       421\n",
            "       video       0.94      0.22      0.36       408\n",
            "    yazarlar       0.61      0.97      0.75       392\n",
            "\n",
            "    accuracy                           0.72      2000\n",
            "   macro avg       0.77      0.72      0.69      2000\n",
            "weighted avg       0.77      0.72      0.69      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "\t\tBest params: {'alpha': 0.01}\n",
            "\t\tValidation Score (Fine-Tuning): 0.78825\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Naive Bayesian Fine-Tuned (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.85      0.83       395\n",
            "        spor       0.91      0.95      0.93       384\n",
            "     turkiye       0.64      0.67      0.66       421\n",
            "       video       0.76      0.46      0.58       408\n",
            "    yazarlar       0.77      0.96      0.85       392\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.78      0.78      0.77      2000\n",
            "weighted avg       0.77      0.78      0.77      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.74\n",
            "Accuracy Score for test data: 0.717\n",
            "Accuracy Score for test data (fine-tuned): 0.7755 \n",
            "\n",
            "\n",
            "\n",
            "*** Final Results ***\n",
            "Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal  -->\t 0.742\n",
            "Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal(fineTuned)  -->\t 0.781\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal  -->\t 0.7055\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal(fineTuned)  -->\t 0.7765\n",
            "Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal  -->\t 0.7465\n",
            "Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal(fineTuned)  -->\t 0.7795\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal  -->\t 0.717\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal(fineTuned)  -->\t 0.7755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctYV-HgCWZo1",
        "outputId": "f8bb26a6-91bb-4318-f8c8-60dcb4948868"
      },
      "source": [
        "loopAllForNB(data_text_processed, data_label, test_data_text_processed, test_data_label, \"preprocessed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting data: Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "Classification Report for Naive Bayesian (Validation) --> Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.84      0.83       154\n",
            "        spor       0.89      0.97      0.93       151\n",
            "     turkiye       0.61      0.83      0.71       168\n",
            "       video       0.88      0.24      0.38       156\n",
            "    yazarlar       0.76      0.91      0.83       171\n",
            "\n",
            "    accuracy                           0.76       800\n",
            "   macro avg       0.79      0.76      0.74       800\n",
            "weighted avg       0.79      0.76      0.74       800\n",
            "\n",
            "Classification Report for Naive Bayesian (Test) --> Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.80      0.85      0.82       395\n",
            "        spor       0.89      0.96      0.92       384\n",
            "     turkiye       0.58      0.78      0.67       421\n",
            "       video       0.93      0.22      0.36       408\n",
            "    yazarlar       0.75      0.96      0.84       392\n",
            "\n",
            "    accuracy                           0.75      2000\n",
            "   macro avg       0.79      0.75      0.72      2000\n",
            "weighted avg       0.79      0.75      0.72      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
            "\t\tBest params: {'alpha': 0.1}\n",
            "\t\tValidation Score (Fine-Tuning): 0.7863749999999999\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Naive Bayesian Fine-Tuned (Test) --> Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.80      0.84      0.82       395\n",
            "        spor       0.91      0.95      0.93       384\n",
            "     turkiye       0.67      0.65      0.66       421\n",
            "       video       0.71      0.53      0.61       408\n",
            "    yazarlar       0.79      0.95      0.86       392\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.78      0.79      0.78      2000\n",
            "weighted avg       0.77      0.78      0.77      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.76375\n",
            "Accuracy Score for test data: 0.749\n",
            "Accuracy Score for test data (fine-tuned): 0.7805 \n",
            "\n",
            "\n",
            "\n",
            "Fitting data: Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "Classification Report for Naive Bayesian (Validation) --> Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.74      0.78       154\n",
            "        spor       0.89      0.97      0.93       151\n",
            "     turkiye       0.65      0.74      0.69       168\n",
            "       video       0.94      0.29      0.45       156\n",
            "    yazarlar       0.62      0.94      0.75       171\n",
            "\n",
            "    accuracy                           0.74       800\n",
            "   macro avg       0.79      0.74      0.72       800\n",
            "weighted avg       0.78      0.74      0.72       800\n",
            "\n",
            "Classification Report for Naive Bayesian (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.81      0.77      0.79       395\n",
            "        spor       0.90      0.94      0.92       384\n",
            "     turkiye       0.59      0.68      0.64       421\n",
            "       video       0.94      0.23      0.37       408\n",
            "    yazarlar       0.61      0.98      0.75       392\n",
            "\n",
            "    accuracy                           0.72      2000\n",
            "   macro avg       0.77      0.72      0.69      2000\n",
            "weighted avg       0.77      0.72      0.69      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "\t\tBest params: {'alpha': 0.01}\n",
            "\t\tValidation Score (Fine-Tuning): 0.787625\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Naive Bayesian Fine-Tuned (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.84      0.83       395\n",
            "        spor       0.91      0.95      0.93       384\n",
            "     turkiye       0.64      0.67      0.66       421\n",
            "       video       0.76      0.48      0.59       408\n",
            "    yazarlar       0.77      0.96      0.85       392\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.78      0.78      0.77      2000\n",
            "weighted avg       0.78      0.78      0.77      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.73875\n",
            "Accuracy Score for test data: 0.717\n",
            "Accuracy Score for test data (fine-tuned): 0.776 \n",
            "\n",
            "\n",
            "\n",
            "Fitting data: Vectorizer Type: TF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "Classification Report for Naive Bayesian (Validation) --> Vectorizer Type: TF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.84      0.83       154\n",
            "        spor       0.89      0.97      0.93       151\n",
            "     turkiye       0.62      0.84      0.71       168\n",
            "       video       0.89      0.26      0.40       156\n",
            "    yazarlar       0.77      0.91      0.83       171\n",
            "\n",
            "    accuracy                           0.77       800\n",
            "   macro avg       0.80      0.77      0.74       800\n",
            "weighted avg       0.79      0.77      0.74       800\n",
            "\n",
            "Classification Report for Naive Bayesian (Test) --> Vectorizer Type: TF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.79      0.85      0.82       395\n",
            "        spor       0.89      0.96      0.92       384\n",
            "     turkiye       0.58      0.78      0.67       421\n",
            "       video       0.93      0.23      0.36       408\n",
            "    yazarlar       0.76      0.96      0.84       392\n",
            "\n",
            "    accuracy                           0.75      2000\n",
            "   macro avg       0.79      0.75      0.72      2000\n",
            "weighted avg       0.79      0.75      0.72      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)\n",
            "\t\tBest params: {'alpha': 0.1}\n",
            "\t\tValidation Score (Fine-Tuning): 0.786125\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Naive Bayesian Fine-Tuned (Test) --> Vectorizer Type: TF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.80      0.84      0.82       395\n",
            "        spor       0.91      0.95      0.93       384\n",
            "     turkiye       0.67      0.65      0.66       421\n",
            "       video       0.71      0.53      0.61       408\n",
            "    yazarlar       0.79      0.95      0.86       392\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.78      0.79      0.78      2000\n",
            "weighted avg       0.77      0.78      0.77      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.7675\n",
            "Accuracy Score for test data: 0.75\n",
            "Accuracy Score for test data (fine-tuned): 0.781 \n",
            "\n",
            "\n",
            "\n",
            "Fitting data: Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "Classification Report for Naive Bayesian (Validation) --> Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.75      0.78       154\n",
            "        spor       0.89      0.97      0.93       151\n",
            "     turkiye       0.64      0.73      0.69       168\n",
            "       video       0.92      0.29      0.45       156\n",
            "    yazarlar       0.63      0.94      0.75       171\n",
            "\n",
            "    accuracy                           0.74       800\n",
            "   macro avg       0.78      0.74      0.72       800\n",
            "weighted avg       0.77      0.74      0.72       800\n",
            "\n",
            "Classification Report for Naive Bayesian (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.80      0.78      0.79       395\n",
            "        spor       0.90      0.94      0.92       384\n",
            "     turkiye       0.60      0.70      0.64       421\n",
            "       video       0.94      0.24      0.38       408\n",
            "    yazarlar       0.61      0.97      0.75       392\n",
            "\n",
            "    accuracy                           0.72      2000\n",
            "   macro avg       0.77      0.73      0.70      2000\n",
            "weighted avg       0.77      0.72      0.69      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "\t\tBest params: {'alpha': 0.01}\n",
            "\t\tValidation Score (Fine-Tuning): 0.78775\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Naive Bayesian Fine-Tuned (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.84      0.83       395\n",
            "        spor       0.91      0.95      0.93       384\n",
            "     turkiye       0.64      0.68      0.66       421\n",
            "       video       0.76      0.48      0.59       408\n",
            "    yazarlar       0.77      0.96      0.86       392\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.78      0.78      0.77      2000\n",
            "weighted avg       0.78      0.78      0.77      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.7375\n",
            "Accuracy Score for test data: 0.7205\n",
            "Accuracy Score for test data (fine-tuned): 0.777 \n",
            "\n",
            "\n",
            "\n",
            "*** Final Results ***\n",
            "Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: preprocessed  -->\t 0.749\n",
            "Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: preprocessed(fineTuned)  -->\t 0.7805\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: preprocessed  -->\t 0.717\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: preprocessed(fineTuned)  -->\t 0.776\n",
            "Vectorizer Type: TF\tInclude Stopwords: no\tData Type: preprocessed  -->\t 0.75\n",
            "Vectorizer Type: TF\tInclude Stopwords: no\tData Type: preprocessed(fineTuned)  -->\t 0.781\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: preprocessed  -->\t 0.7205\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: preprocessed(fineTuned)  -->\t 0.777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3WEii1MWuda"
      },
      "source": [
        "# *** Final Results ***\n",
        "# Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal  -->  0.742\n",
        "# Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal(fineTuned)  -->  0.781\n",
        "# Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal  -->  0.7055\n",
        "# Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal(fineTuned)  -->  0.7765\n",
        "# Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal  -->  0.7465\n",
        "# Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal(fineTuned)  -->  0.7795\n",
        "# Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal  -->  0.717\n",
        "# Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal(fineTuned)  -->  0.7755"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STK0RoNtyjrN"
      },
      "source": [
        "vectorizerList = [\"TF\", \"TF-IDF\"]\n",
        "includeStopWordsList = [ \"yes\", \"no\" ]\n",
        "\n",
        "def loopAllforLogres(data_text, data_label, test_data_text, test_data_label, data_type):\n",
        "\n",
        "    outFile = open(\"/content/drive/MyDrive/CS 445 Project 3/Logistic Regression_\" + data_type + \".txt\", \"w\")\n",
        "\n",
        "    iterLimit = 400\n",
        "\n",
        "    test_results = {}\n",
        "\n",
        "    for includeStopWords in includeStopWordsList:\n",
        "        for vectorizerType in vectorizerList:\n",
        "            if includeStopWords == \"yes\" and vectorizerType == \"TF\":\n",
        "                vectorizer = CountVectorizer()\n",
        "            \n",
        "            elif includeStopWords == \"yes\" and vectorizerType == \"TF-IDF\":\n",
        "                vectorizer = TfidfVectorizer()\n",
        "            \n",
        "            elif includeStopWords == \"no\" and vectorizerType == \"TF\":\n",
        "                vectorizer = CountVectorizer(stop_words=stopWords)\n",
        "            \n",
        "            elif includeStopWords == \"no\" and vectorizerType == \"TF-IDF\":\n",
        "                vectorizer = TfidfVectorizer(stop_words=stopWords)\n",
        "\n",
        "            else:\n",
        "                print(\"What are doing here???\")\n",
        "                return\n",
        "\n",
        "            X_train, X_valid, y_train, y_valid = train_test_split(data_text, data_label, test_size=0.1, random_state=1)\n",
        "\n",
        "            title = \"Vectorizer Type: \" + vectorizerType + \"\\tInclude Stopwords: \" + includeStopWords + \"\\tData Type: \" + data_type\n",
        "            \n",
        "            outFile.write(\"*** Start For \" + title + \" ***\\n\")\n",
        "\n",
        "            model = make_pipeline(vectorizer, LogisticRegression(max_iter=iterLimit, random_state=42))\n",
        "\n",
        "            print(\"Fitting data:\", title)\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Predict the Validation Data\n",
        "            predictions = model.predict(X_valid)\n",
        "\n",
        "            # Accuracy of the Naive Bayes for validation\n",
        "            accuracy_validation_logres = accuracy_score(y_valid, predictions)\n",
        "\n",
        "            print(\"Classification Report for Logistic Regression (Validation) -->\", title)\n",
        "            print(classification_report(y_valid, predictions))\n",
        "            \n",
        "            outFile.write(\"Classification Report for Logistic Regression (Validation) --> \" + title + \"\\n\")\n",
        "            outFile.write(classification_report(y_valid, predictions))\n",
        "            outFile.write(\"\\n\\n\\n\")\n",
        "\n",
        "            # Accuracy of the Naive Bayes for test\n",
        "            model.fit(data_text, data_label)\n",
        "\n",
        "            predictions = model.predict(test_data_text)\n",
        "\n",
        "            accuracy_test_logres = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "            print(\"Classification Report for Logistic Regression (Test) -->\", title)\n",
        "            print(classification_report(test_data_label, predictions))\n",
        "\n",
        "            outFile.write(\"Classification Report for Logistic Regression (Test) --> \" + title + \"\\n\")\n",
        "            outFile.write(classification_report(test_data_label, predictions))\n",
        "            outFile.write(\"\\n\\n\\n\")\n",
        "\n",
        "            # Accuracy with Fine-Tuning (GridSearchCV)\n",
        "            print(\"\\n*** GridSearchCV Starts ***\\n\")\n",
        "            vec_x = vectorizer.fit_transform(data_text)\n",
        "\n",
        "            grid = GridSearchCV(LogisticRegression(max_iter=iterLimit, random_state=42), param_grid={'C': [0.001,0.01,0.1,1,10,100]}, scoring=\"accuracy\")\n",
        "            grid.fit(vec_x, data_label)\n",
        "\n",
        "            print(\"\\t\\tBest estimators:\", grid.best_estimator_)\n",
        "            print(\"\\t\\tBest params:\", grid.best_params_)\n",
        "            print(\"\\t\\tValidation Score (Fine-Tuning):\", grid.best_score_)\n",
        "\n",
        "            # Fine-Tuned NaiveBayes\n",
        "            best_C = grid.best_params_[\"C\"]\n",
        "            print(\"\\n*** Test Data Starts with Fine-Tune ***\\n\")\n",
        "            model = make_pipeline(vectorizer, LogisticRegression(C=best_C, max_iter=iterLimit, random_state=42))\n",
        "\n",
        "            model.fit(data_text, data_label)\n",
        "            predictions = model.predict(test_data_text)\n",
        "\n",
        "            accuracy_test_logres_fine_tuned = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "            print(\"Classification Report for Logistic Regression Fine-Tuned (Test) -->\", title)\n",
        "            print(classification_report(test_data_label, predictions))\n",
        "\n",
        "            outFile.write(\"Classification Report for Logistic Regression Fine-Tuned (Test) --> \" + title + \"\\n\")\n",
        "            outFile.write(classification_report(test_data_label, predictions))\n",
        "            outFile.write(\"\\n\\n\")\n",
        "\n",
        "\n",
        "            print(\"\\n\\n*** Accuracy Results ***\")\n",
        "            print(\"Accuracy Score for validation data:\", accuracy_validation_logres)\n",
        "            print(\"Accuracy Score for test data:\", accuracy_test_logres)\n",
        "            print(\"Accuracy Score for test data (fine-tuned):\", accuracy_test_logres_fine_tuned, \"\\n\\n\\n\")\n",
        "\n",
        "            test_results[title] = accuracy_test_logres\n",
        "            test_results[title+\"(fineTuned)\"] = accuracy_test_logres_fine_tuned\n",
        "\n",
        "            outFile.write(\"\\n\\n*** Accuracy Results ***\\n\")\n",
        "            outFile.write(\"Accuracy Score for validation data: \" + str(accuracy_validation_logres) + \"\\n\" )\n",
        "            outFile.write(\"Accuracy Score for test data: \" + str(accuracy_test_logres) + \"\\n\" )\n",
        "            outFile.write(\"Accuracy Score for test data (fine-tuned): \" + str(accuracy_test_logres_fine_tuned) + \"\\n\\n\\n\" )\n",
        "            \n",
        "            outFile.write(\"*** End For \" + title + \" ***\\n\\n\\n\")\n",
        "\n",
        "    print(\"*** Final Results ***\")\n",
        "    outFile.write(\"*** Final Results ***\\n\")\n",
        "    for key, value in test_results.items():\n",
        "        print(key, \" -->\\t\", value)\n",
        "        outFile.write( key + \" :\\t\" + str(value) + \"\\n\" )\n",
        "\n",
        "    outFile.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA7uHzFs0tch",
        "outputId": "53846569-788c-4e89-8281-ab6c846a7b53"
      },
      "source": [
        "loopAllforLogres(data_text, data_label, test_data_text, test_data_label, \"normal\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting data: Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal\n",
            "Classification Report for Logistic Regression (Validation) --> Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.86      0.81      0.83       154\n",
            "        spor       0.93      0.93      0.93       151\n",
            "     turkiye       0.79      0.76      0.77       168\n",
            "       video       0.77      0.86      0.81       156\n",
            "    yazarlar       0.93      0.92      0.93       171\n",
            "\n",
            "    accuracy                           0.86       800\n",
            "   macro avg       0.86      0.86      0.86       800\n",
            "weighted avg       0.86      0.86      0.86       800\n",
            "\n",
            "Classification Report for Logistic Regression (Test) --> Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.84      0.84       395\n",
            "        spor       0.94      0.90      0.92       384\n",
            "     turkiye       0.80      0.69      0.74       421\n",
            "       video       0.75      0.88      0.81       408\n",
            "    yazarlar       0.91      0.92      0.91       392\n",
            "\n",
            "    accuracy                           0.84      2000\n",
            "   macro avg       0.85      0.85      0.84      2000\n",
            "weighted avg       0.85      0.84      0.84      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=400,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\t\tBest params: {'C': 0.1}\n",
            "\t\tValidation Score (Fine-Tuning): 0.842\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Logistic Regression Fine-Tuned (Test) --> Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.85      0.85      0.85       395\n",
            "        spor       0.95      0.91      0.93       384\n",
            "     turkiye       0.83      0.70      0.76       421\n",
            "       video       0.75      0.89      0.81       408\n",
            "    yazarlar       0.91      0.92      0.92       392\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.86      0.85      0.85      2000\n",
            "weighted avg       0.86      0.85      0.85      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.85625\n",
            "Accuracy Score for test data: 0.8435\n",
            "Accuracy Score for test data (fine-tuned): 0.852 \n",
            "\n",
            "\n",
            "\n",
            "Fitting data: Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal\n",
            "Classification Report for Logistic Regression (Validation) --> Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.84      0.84      0.84       154\n",
            "        spor       0.91      0.94      0.93       151\n",
            "     turkiye       0.78      0.76      0.77       168\n",
            "       video       0.80      0.78      0.79       156\n",
            "    yazarlar       0.88      0.92      0.90       171\n",
            "\n",
            "    accuracy                           0.84       800\n",
            "   macro avg       0.84      0.85      0.84       800\n",
            "weighted avg       0.84      0.84      0.84       800\n",
            "\n",
            "Classification Report for Logistic Regression (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.86      0.84       395\n",
            "        spor       0.94      0.94      0.94       384\n",
            "     turkiye       0.78      0.68      0.73       421\n",
            "       video       0.77      0.78      0.78       408\n",
            "    yazarlar       0.87      0.94      0.91       392\n",
            "\n",
            "    accuracy                           0.84      2000\n",
            "   macro avg       0.84      0.84      0.84      2000\n",
            "weighted avg       0.83      0.84      0.83      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=400,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\t\tBest params: {'C': 100}\n",
            "\t\tValidation Score (Fine-Tuning): 0.840625\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Logistic Regression Fine-Tuned (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.81      0.87      0.84       395\n",
            "        spor       0.94      0.95      0.94       384\n",
            "     turkiye       0.78      0.71      0.75       421\n",
            "       video       0.79      0.77      0.78       408\n",
            "    yazarlar       0.91      0.95      0.93       392\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.85      0.85      0.85      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.845\n",
            "Accuracy Score for test data: 0.8365\n",
            "Accuracy Score for test data (fine-tuned): 0.847 \n",
            "\n",
            "\n",
            "\n",
            "Fitting data: Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal\n",
            "Classification Report for Logistic Regression (Validation) --> Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.85      0.79      0.82       154\n",
            "        spor       0.94      0.95      0.95       151\n",
            "     turkiye       0.78      0.74      0.76       168\n",
            "       video       0.77      0.85      0.80       156\n",
            "    yazarlar       0.91      0.91      0.91       171\n",
            "\n",
            "    accuracy                           0.85       800\n",
            "   macro avg       0.85      0.85      0.85       800\n",
            "weighted avg       0.85      0.85      0.85       800\n",
            "\n",
            "Classification Report for Logistic Regression (Test) --> Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.84      0.84       395\n",
            "        spor       0.94      0.92      0.93       384\n",
            "     turkiye       0.82      0.68      0.75       421\n",
            "       video       0.75      0.88      0.81       408\n",
            "    yazarlar       0.92      0.92      0.92       392\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.85      0.85      0.85      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=400,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\t\tBest params: {'C': 1}\n",
            "\t\tValidation Score (Fine-Tuning): 0.84375\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Logistic Regression Fine-Tuned (Test) --> Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.84      0.84       395\n",
            "        spor       0.94      0.92      0.93       384\n",
            "     turkiye       0.82      0.68      0.75       421\n",
            "       video       0.75      0.88      0.81       408\n",
            "    yazarlar       0.92      0.92      0.92       392\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.85      0.85      0.85      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.8475\n",
            "Accuracy Score for test data: 0.8475\n",
            "Accuracy Score for test data (fine-tuned): 0.8475 \n",
            "\n",
            "\n",
            "\n",
            "Fitting data: Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal\n",
            "Classification Report for Logistic Regression (Validation) --> Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.83      0.83       154\n",
            "        spor       0.91      0.95      0.93       151\n",
            "     turkiye       0.75      0.72      0.73       168\n",
            "       video       0.76      0.74      0.75       156\n",
            "    yazarlar       0.89      0.89      0.89       171\n",
            "\n",
            "    accuracy                           0.83       800\n",
            "   macro avg       0.82      0.83      0.83       800\n",
            "weighted avg       0.82      0.83      0.83       800\n",
            "\n",
            "Classification Report for Logistic Regression (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.87      0.84       395\n",
            "        spor       0.93      0.93      0.93       384\n",
            "     turkiye       0.77      0.69      0.73       421\n",
            "       video       0.78      0.76      0.77       408\n",
            "    yazarlar       0.86      0.92      0.89       392\n",
            "\n",
            "    accuracy                           0.83      2000\n",
            "   macro avg       0.83      0.84      0.83      2000\n",
            "weighted avg       0.83      0.83      0.83      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=400,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\t\tBest params: {'C': 100}\n",
            "\t\tValidation Score (Fine-Tuning): 0.83925\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Logistic Regression Fine-Tuned (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.87      0.85       395\n",
            "        spor       0.94      0.94      0.94       384\n",
            "     turkiye       0.79      0.72      0.75       421\n",
            "       video       0.78      0.77      0.78       408\n",
            "    yazarlar       0.91      0.95      0.93       392\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.85      0.85      0.85      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.82625\n",
            "Accuracy Score for test data: 0.8325\n",
            "Accuracy Score for test data (fine-tuned): 0.8475 \n",
            "\n",
            "\n",
            "\n",
            "*** Final Results ***\n",
            "Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal  -->\t 0.8435\n",
            "Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: normal(fineTuned)  -->\t 0.852\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal  -->\t 0.8365\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: normal(fineTuned)  -->\t 0.847\n",
            "Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal  -->\t 0.8475\n",
            "Vectorizer Type: TF\tInclude Stopwords: no\tData Type: normal(fineTuned)  -->\t 0.8475\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal  -->\t 0.8325\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: normal(fineTuned)  -->\t 0.8475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWq5jS0G00oB",
        "outputId": "68951ebb-e613-460c-9ee9-4c4b7cfb19cb"
      },
      "source": [
        "loopAllforLogres(data_text, data_label, test_data_text, test_data_label, \"preprocessed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting data: Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "Classification Report for Logistic Regression (Validation) --> Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.86      0.81      0.83       154\n",
            "        spor       0.93      0.93      0.93       151\n",
            "     turkiye       0.79      0.76      0.77       168\n",
            "       video       0.77      0.86      0.81       156\n",
            "    yazarlar       0.93      0.92      0.93       171\n",
            "\n",
            "    accuracy                           0.86       800\n",
            "   macro avg       0.86      0.86      0.86       800\n",
            "weighted avg       0.86      0.86      0.86       800\n",
            "\n",
            "Classification Report for Logistic Regression (Test) --> Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.84      0.84       395\n",
            "        spor       0.94      0.90      0.92       384\n",
            "     turkiye       0.80      0.69      0.74       421\n",
            "       video       0.75      0.88      0.81       408\n",
            "    yazarlar       0.91      0.92      0.91       392\n",
            "\n",
            "    accuracy                           0.84      2000\n",
            "   macro avg       0.85      0.85      0.84      2000\n",
            "weighted avg       0.85      0.84      0.84      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=400,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\t\tBest params: {'C': 0.1}\n",
            "\t\tValidation Score (Fine-Tuning): 0.842\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Logistic Regression Fine-Tuned (Test) --> Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.85      0.85      0.85       395\n",
            "        spor       0.95      0.91      0.93       384\n",
            "     turkiye       0.83      0.70      0.76       421\n",
            "       video       0.75      0.89      0.81       408\n",
            "    yazarlar       0.91      0.92      0.92       392\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.86      0.85      0.85      2000\n",
            "weighted avg       0.86      0.85      0.85      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.85625\n",
            "Accuracy Score for test data: 0.8435\n",
            "Accuracy Score for test data (fine-tuned): 0.852 \n",
            "\n",
            "\n",
            "\n",
            "Fitting data: Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "Classification Report for Logistic Regression (Validation) --> Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.84      0.84      0.84       154\n",
            "        spor       0.91      0.94      0.93       151\n",
            "     turkiye       0.78      0.76      0.77       168\n",
            "       video       0.80      0.78      0.79       156\n",
            "    yazarlar       0.88      0.92      0.90       171\n",
            "\n",
            "    accuracy                           0.84       800\n",
            "   macro avg       0.84      0.85      0.84       800\n",
            "weighted avg       0.84      0.84      0.84       800\n",
            "\n",
            "Classification Report for Logistic Regression (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.86      0.84       395\n",
            "        spor       0.94      0.94      0.94       384\n",
            "     turkiye       0.78      0.68      0.73       421\n",
            "       video       0.77      0.78      0.78       408\n",
            "    yazarlar       0.87      0.94      0.91       392\n",
            "\n",
            "    accuracy                           0.84      2000\n",
            "   macro avg       0.84      0.84      0.84      2000\n",
            "weighted avg       0.83      0.84      0.83      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=400,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\t\tBest params: {'C': 100}\n",
            "\t\tValidation Score (Fine-Tuning): 0.840625\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Logistic Regression Fine-Tuned (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.81      0.87      0.84       395\n",
            "        spor       0.94      0.95      0.94       384\n",
            "     turkiye       0.78      0.71      0.75       421\n",
            "       video       0.79      0.77      0.78       408\n",
            "    yazarlar       0.91      0.95      0.93       392\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.85      0.85      0.85      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.845\n",
            "Accuracy Score for test data: 0.8365\n",
            "Accuracy Score for test data (fine-tuned): 0.847 \n",
            "\n",
            "\n",
            "\n",
            "Fitting data: Vectorizer Type: TF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "Classification Report for Logistic Regression (Validation) --> Vectorizer Type: TF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.85      0.79      0.82       154\n",
            "        spor       0.94      0.95      0.95       151\n",
            "     turkiye       0.78      0.74      0.76       168\n",
            "       video       0.77      0.85      0.80       156\n",
            "    yazarlar       0.91      0.91      0.91       171\n",
            "\n",
            "    accuracy                           0.85       800\n",
            "   macro avg       0.85      0.85      0.85       800\n",
            "weighted avg       0.85      0.85      0.85       800\n",
            "\n",
            "Classification Report for Logistic Regression (Test) --> Vectorizer Type: TF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.84      0.84       395\n",
            "        spor       0.94      0.92      0.93       384\n",
            "     turkiye       0.82      0.68      0.75       421\n",
            "       video       0.75      0.88      0.81       408\n",
            "    yazarlar       0.92      0.92      0.92       392\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.85      0.85      0.85      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=400,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\t\tBest params: {'C': 1}\n",
            "\t\tValidation Score (Fine-Tuning): 0.84375\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Logistic Regression Fine-Tuned (Test) --> Vectorizer Type: TF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.84      0.84       395\n",
            "        spor       0.94      0.92      0.93       384\n",
            "     turkiye       0.82      0.68      0.75       421\n",
            "       video       0.75      0.88      0.81       408\n",
            "    yazarlar       0.92      0.92      0.92       392\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.85      0.85      0.85      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.8475\n",
            "Accuracy Score for test data: 0.8475\n",
            "Accuracy Score for test data (fine-tuned): 0.8475 \n",
            "\n",
            "\n",
            "\n",
            "Fitting data: Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "Classification Report for Logistic Regression (Validation) --> Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.83      0.83       154\n",
            "        spor       0.91      0.95      0.93       151\n",
            "     turkiye       0.75      0.72      0.73       168\n",
            "       video       0.76      0.74      0.75       156\n",
            "    yazarlar       0.89      0.89      0.89       171\n",
            "\n",
            "    accuracy                           0.83       800\n",
            "   macro avg       0.82      0.83      0.83       800\n",
            "weighted avg       0.82      0.83      0.83       800\n",
            "\n",
            "Classification Report for Logistic Regression (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.87      0.84       395\n",
            "        spor       0.93      0.93      0.93       384\n",
            "     turkiye       0.77      0.69      0.73       421\n",
            "       video       0.78      0.76      0.77       408\n",
            "    yazarlar       0.86      0.92      0.89       392\n",
            "\n",
            "    accuracy                           0.83      2000\n",
            "   macro avg       0.83      0.84      0.83      2000\n",
            "weighted avg       0.83      0.83      0.83      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "\t\tBest estimators: LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=400,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\t\tBest params: {'C': 100}\n",
            "\t\tValidation Score (Fine-Tuning): 0.83925\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Logistic Regression Fine-Tuned (Test) --> Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: preprocessed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.87      0.85       395\n",
            "        spor       0.94      0.94      0.94       384\n",
            "     turkiye       0.79      0.72      0.75       421\n",
            "       video       0.78      0.77      0.78       408\n",
            "    yazarlar       0.91      0.95      0.93       392\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.85      0.85      0.85      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.82625\n",
            "Accuracy Score for test data: 0.8325\n",
            "Accuracy Score for test data (fine-tuned): 0.8475 \n",
            "\n",
            "\n",
            "\n",
            "*** Final Results ***\n",
            "Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: preprocessed  -->\t 0.8435\n",
            "Vectorizer Type: TF\tInclude Stopwords: yes\tData Type: preprocessed(fineTuned)  -->\t 0.852\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: preprocessed  -->\t 0.8365\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: yes\tData Type: preprocessed(fineTuned)  -->\t 0.847\n",
            "Vectorizer Type: TF\tInclude Stopwords: no\tData Type: preprocessed  -->\t 0.8475\n",
            "Vectorizer Type: TF\tInclude Stopwords: no\tData Type: preprocessed(fineTuned)  -->\t 0.8475\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: preprocessed  -->\t 0.8325\n",
            "Vectorizer Type: TF-IDF\tInclude Stopwords: no\tData Type: preprocessed(fineTuned)  -->\t 0.8475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVZXDuhNKFZQ"
      },
      "source": [
        "# Naive Bayes Classifier with TF-IDF Vectorizer No Stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL6_hVaCuMry",
        "outputId": "d3e9b94f-f3fb-479d-9afe-dad15bedb155"
      },
      "source": [
        "# Build the model\r\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\r\n",
        "\r\n",
        "# Fit the Train Data\r\n",
        "model.fit(X_train, y_train)\r\n",
        "\r\n",
        "print(\"\\n*** Validation Data Starts ***\\n\")\r\n",
        "\r\n",
        "# Predict the Validation Data\r\n",
        "predictions = model.predict(X_valid)\r\n",
        "\r\n",
        "# Accuracy of the Naive Bayes for validation\r\n",
        "accuracy_validation_nb = accuracy_score(y_valid, predictions)\r\n",
        "\r\n",
        "print(\"Classification Report for Naive Bayesian (Validation):\")\r\n",
        "print(classification_report(y_valid, predictions))\r\n",
        "\r\n",
        "# Accuracy of the Naive Bayes for test\r\n",
        "print(\"\\n*** Test Data Starts ***\\n\")\r\n",
        "model.fit(data_text, data_label)\r\n",
        "\r\n",
        "predictions = model.predict(test_data_text)\r\n",
        "\r\n",
        "accuracy_test_nb = accuracy_score(test_data_label, predictions)\r\n",
        "\r\n",
        "print(\"Classification Report for Naive Bayesian (Test):\")\r\n",
        "print(classification_report(test_data_label, predictions))\r\n",
        "\r\n",
        "# Accuract with Fine-Tuning (GridSearchCV)\r\n",
        "print(\"\\n*** GridSearchCV Starts ***\\n\")\r\n",
        "vectorizer = TfidfVectorizer()\r\n",
        "vec_x = vectorizer.fit_transform(data_text)\r\n",
        "\r\n",
        "grid = GridSearchCV(MultinomialNB(), param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001]}, scoring=\"accuracy\")\r\n",
        "grid.fit(vec_x, data_label)\r\n",
        "\r\n",
        "print(\"Best estimators:\", grid.best_estimator_)\r\n",
        "print(\"Best params:\", grid.best_params_)\r\n",
        "print(\"Validation Score (Fine-Tuning):\", grid.best_score_)\r\n",
        "\r\n",
        "# Fine-Tuned NaiveBayes\r\n",
        "best_alpha = grid.best_params_[\"alpha\"]\r\n",
        "print(\"\\n*** Test Data Starts with Fine-Tune ***\\n\")\r\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB(alpha=best_alpha))\r\n",
        "\r\n",
        "model.fit(data_text, data_label)\r\n",
        "predictions = model.predict(test_data_text)\r\n",
        "\r\n",
        "accuracy_test_nb_fine_tuned = accuracy_score(test_data_label, predictions)\r\n",
        "\r\n",
        "print(\"Classification Report for Naive Bayesian Fine-Tuned (Test):\")\r\n",
        "print(classification_report(test_data_label, predictions))\r\n",
        "\r\n",
        "\r\n",
        "print(\"\\n\\n*** Accuracy Results ***\")\r\n",
        "print(\"Accuracy Score for validation data:\", accuracy_validation_nb)\r\n",
        "print(\"Accuracy Score for test data:\", accuracy_test_nb)\r\n",
        "print(\"Accuracy Score for test data (fine-tuned):\", accuracy_test_nb_fine_tuned)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** Validation Data Starts ***\n",
            "\n",
            "Classification Report for Naive Bayesian (Validation):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.74      0.78       154\n",
            "        spor       0.89      0.97      0.93       151\n",
            "     turkiye       0.65      0.74      0.69       168\n",
            "       video       0.94      0.29      0.45       156\n",
            "    yazarlar       0.62      0.94      0.75       171\n",
            "\n",
            "    accuracy                           0.74       800\n",
            "   macro avg       0.79      0.74      0.72       800\n",
            "weighted avg       0.78      0.74      0.72       800\n",
            "\n",
            "\n",
            "*** Test Data Starts ***\n",
            "\n",
            "Classification Report for Naive Bayesian (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.81      0.77      0.79       395\n",
            "        spor       0.90      0.94      0.92       384\n",
            "     turkiye       0.59      0.68      0.64       421\n",
            "       video       0.94      0.23      0.37       408\n",
            "    yazarlar       0.61      0.98      0.75       392\n",
            "\n",
            "    accuracy                           0.72      2000\n",
            "   macro avg       0.77      0.72      0.69      2000\n",
            "weighted avg       0.77      0.72      0.69      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "Best estimators: MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "Best params: {'alpha': 0.01}\n",
            "Validation Score (Fine-Tuning): 0.787625\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Naive Bayesian Fine-Tuned (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.84      0.83       395\n",
            "        spor       0.91      0.95      0.93       384\n",
            "     turkiye       0.64      0.67      0.66       421\n",
            "       video       0.76      0.48      0.59       408\n",
            "    yazarlar       0.77      0.96      0.85       392\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.78      0.78      0.77      2000\n",
            "weighted avg       0.78      0.78      0.77      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.73875\n",
            "Accuracy Score for test data: 0.717\n",
            "Accuracy Score for test data (fine-tuned): 0.776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzTGOCPWzIeV"
      },
      "source": [
        "# Naive Bayes Classifier with TF-IDF Vectorizer with Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Nar0Hi7zFLo",
        "outputId": "130c4d7c-5053-4350-8ab9-c0f8f8f1bc53"
      },
      "source": [
        "# Build the model\n",
        "model = make_pipeline(TfidfVectorizer(stop_words=stopWords), MultinomialNB())\n",
        "\n",
        "# Fit the Train Data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n*** Validation Data Starts ***\\n\")\n",
        "\n",
        "# Predict the Validation Data\n",
        "predictions = model.predict(X_valid)\n",
        "\n",
        "# Accuracy of the Naive Bayes for validation\n",
        "accuracy_validation_nb = accuracy_score(y_valid, predictions)\n",
        "\n",
        "print(\"Classification Report for Naive Bayesian (Validation):\")\n",
        "print(classification_report(y_valid, predictions))\n",
        "\n",
        "# Accuracy of the Naive Bayes for test\n",
        "print(\"\\n*** Test Data Starts ***\\n\")\n",
        "model.fit(data_text, data_label)\n",
        "\n",
        "predictions = model.predict(test_data_text)\n",
        "\n",
        "accuracy_test_nb = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "print(\"Classification Report for Naive Bayesian (Test):\")\n",
        "print(classification_report(test_data_label, predictions))\n",
        "\n",
        "# Accuract with Fine-Tuning (GridSearchCV)\n",
        "print(\"\\n*** GridSearchCV Starts ***\\n\")\n",
        "vectorizer = TfidfVectorizer()\n",
        "vec_x = vectorizer.fit_transform(data_text)\n",
        "\n",
        "grid = GridSearchCV(MultinomialNB(), param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001]}, scoring=\"accuracy\")\n",
        "grid.fit(vec_x, data_label)\n",
        "\n",
        "print(\"Best estimators:\", grid.best_estimator_)\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(\"Validation Score (Fine-Tuning):\", grid.best_score_)\n",
        "\n",
        "# Fine-Tuned NaiveBayes\n",
        "best_alpha = grid.best_params_[\"alpha\"]\n",
        "print(\"\\n*** Test Data Starts with Fine-Tune ***\\n\")\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB(alpha=best_alpha))\n",
        "\n",
        "model.fit(data_text, data_label)\n",
        "predictions = model.predict(test_data_text)\n",
        "\n",
        "accuracy_test_nb_fine_tuned = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "print(\"Classification Report for Naive Bayesian Fine-Tuned (Test):\")\n",
        "print(classification_report(test_data_label, predictions))\n",
        "\n",
        "\n",
        "print(\"\\n\\n*** Accuracy Results ***\")\n",
        "print(\"Accuracy Score for validation data:\", accuracy_validation_nb)\n",
        "print(\"Accuracy Score for test data:\", accuracy_test_nb)\n",
        "print(\"Accuracy Score for test data (fine-tuned):\", accuracy_test_nb_fine_tuned)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** Validation Data Starts ***\n",
            "\n",
            "Classification Report for Naive Bayesian (Validation):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.81      0.77      0.79       154\n",
            "        spor       0.89      0.97      0.93       151\n",
            "     turkiye       0.65      0.74      0.69       168\n",
            "       video       0.96      0.29      0.44       156\n",
            "    yazarlar       0.63      0.93      0.75       171\n",
            "\n",
            "    accuracy                           0.74       800\n",
            "   macro avg       0.79      0.74      0.72       800\n",
            "weighted avg       0.78      0.74      0.72       800\n",
            "\n",
            "\n",
            "*** Test Data Starts ***\n",
            "\n",
            "Classification Report for Naive Bayesian (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.80      0.78      0.79       395\n",
            "        spor       0.90      0.95      0.92       384\n",
            "     turkiye       0.60      0.69      0.64       421\n",
            "       video       0.94      0.22      0.36       408\n",
            "    yazarlar       0.61      0.97      0.75       392\n",
            "\n",
            "    accuracy                           0.72      2000\n",
            "   macro avg       0.77      0.72      0.69      2000\n",
            "weighted avg       0.77      0.72      0.69      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "Best estimators: MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "Best params: {'alpha': 0.01}\n",
            "Validation Score (Fine-Tuning): 0.789125\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Naive Bayesian Fine-Tuned (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.84      0.83       395\n",
            "        spor       0.91      0.95      0.93       384\n",
            "     turkiye       0.64      0.67      0.66       421\n",
            "       video       0.76      0.47      0.58       408\n",
            "    yazarlar       0.76      0.96      0.85       392\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.78      0.78      0.77      2000\n",
            "weighted avg       0.78      0.78      0.77      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.74\n",
            "Accuracy Score for test data: 0.717\n",
            "Accuracy Score for test data (fine-tuned): 0.7765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KC2y7ZKzWwH"
      },
      "source": [
        "# Naive Bayes Classifier with TF Vectorizer NO Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcvN0aGIx2iH",
        "outputId": "b8fab2f3-92cc-45fe-9afa-e28115531b80"
      },
      "source": [
        "# Build the model\n",
        "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
        "\n",
        "# Fit the Train Data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n*** Validation Data Starts ***\\n\")\n",
        "\n",
        "# Predict the Validation Data\n",
        "predictions = model.predict(X_valid)\n",
        "\n",
        "# Accuracy of the Naive Bayes for validation\n",
        "accuracy_validation_nb = accuracy_score(y_valid, predictions)\n",
        "\n",
        "print(\"Classification Report for Naive Bayesian (Validation):\")\n",
        "print(classification_report(y_valid, predictions))\n",
        "\n",
        "# Accuracy of the Naive Bayes for test\n",
        "print(\"\\n*** Test Data Starts ***\\n\")\n",
        "model.fit(data_text, data_label)\n",
        "\n",
        "predictions = model.predict(test_data_text)\n",
        "\n",
        "accuracy_test_nb = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "print(\"Classification Report for Naive Bayesian (Test):\")\n",
        "print(classification_report(test_data_label, predictions))\n",
        "\n",
        "# Accuract with Fine-Tuning (GridSearchCV)\n",
        "print(\"\\n*** GridSearchCV Starts ***\\n\")\n",
        "vectorizer = TfidfVectorizer()\n",
        "vec_x = vectorizer.fit_transform(data_text)\n",
        "\n",
        "grid = GridSearchCV(MultinomialNB(), param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001]}, scoring=\"accuracy\")\n",
        "grid.fit(vec_x, data_label)\n",
        "\n",
        "print(\"Best estimators:\", grid.best_estimator_)\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(\"Validation Score (Fine-Tuning):\", grid.best_score_)\n",
        "\n",
        "# Fine-Tuned NaiveBayes\n",
        "best_alpha = grid.best_params_[\"alpha\"]\n",
        "print(\"\\n*** Test Data Starts with Fine-Tune ***\\n\")\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB(alpha=best_alpha))\n",
        "\n",
        "model.fit(data_text, data_label)\n",
        "predictions = model.predict(test_data_text)\n",
        "\n",
        "accuracy_test_nb_fine_tuned = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "print(\"Classification Report for Naive Bayesian Fine-Tuned (Test):\")\n",
        "print(classification_report(test_data_label, predictions))\n",
        "\n",
        "\n",
        "print(\"\\n\\n*** Accuracy Results ***\")\n",
        "print(\"Accuracy Score for validation data:\", accuracy_validation_nb)\n",
        "print(\"Accuracy Score for test data:\", accuracy_test_nb)\n",
        "print(\"Accuracy Score for test data (fine-tuned):\", accuracy_test_nb_fine_tuned)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** Validation Data Starts ***\n",
            "\n",
            "Classification Report for Naive Bayesian (Validation):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.86      0.84       154\n",
            "        spor       0.89      0.97      0.93       151\n",
            "     turkiye       0.61      0.83      0.71       168\n",
            "       video       0.93      0.24      0.38       156\n",
            "    yazarlar       0.76      0.91      0.83       171\n",
            "\n",
            "    accuracy                           0.76       800\n",
            "   macro avg       0.80      0.76      0.74       800\n",
            "weighted avg       0.80      0.76      0.73       800\n",
            "\n",
            "\n",
            "*** Test Data Starts ***\n",
            "\n",
            "Classification Report for Naive Bayesian (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.80      0.85      0.82       395\n",
            "        spor       0.89      0.95      0.92       384\n",
            "     turkiye       0.58      0.77      0.66       421\n",
            "       video       0.92      0.20      0.32       408\n",
            "    yazarlar       0.72      0.96      0.83       392\n",
            "\n",
            "    accuracy                           0.74      2000\n",
            "   macro avg       0.78      0.75      0.71      2000\n",
            "weighted avg       0.78      0.74      0.71      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "Best estimators: MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "Best params: {'alpha': 0.01}\n",
            "Validation Score (Fine-Tuning): 0.789125\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Naive Bayesian Fine-Tuned (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.84      0.83       395\n",
            "        spor       0.91      0.95      0.93       384\n",
            "     turkiye       0.64      0.67      0.66       421\n",
            "       video       0.76      0.47      0.58       408\n",
            "    yazarlar       0.76      0.96      0.85       392\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.78      0.78      0.77      2000\n",
            "weighted avg       0.78      0.78      0.77      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.76375\n",
            "Accuracy Score for test data: 0.742\n",
            "Accuracy Score for test data (fine-tuned): 0.7765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2ek-0b7zp9r"
      },
      "source": [
        "# Naive Bayes Classifier with TF Vectorizer with Stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSWBx9g1zxkB",
        "outputId": "64a766cc-d700-4246-e942-f6a4aebbf795"
      },
      "source": [
        "# Build the model\n",
        "model = make_pipeline(CountVectorizer(stop_words=stopWords), MultinomialNB())\n",
        "\n",
        "# Fit the Train Data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n*** Validation Data Starts ***\\n\")\n",
        "\n",
        "# Predict the Validation Data\n",
        "predictions = model.predict(X_valid)\n",
        "\n",
        "# Accuracy of the Naive Bayes for validation\n",
        "accuracy_validation_nb = accuracy_score(y_valid, predictions)\n",
        "\n",
        "print(\"Classification Report for Naive Bayesian (Validation):\")\n",
        "print(classification_report(y_valid, predictions))\n",
        "\n",
        "# Accuracy of the Naive Bayes for test\n",
        "print(\"\\n*** Test Data Starts ***\\n\")\n",
        "model.fit(data_text, data_label)\n",
        "\n",
        "predictions = model.predict(test_data_text)\n",
        "\n",
        "accuracy_test_nb = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "print(\"Classification Report for Naive Bayesian (Test):\")\n",
        "print(classification_report(test_data_label, predictions))\n",
        "\n",
        "# Accuract with Fine-Tuning (GridSearchCV)\n",
        "print(\"\\n*** GridSearchCV Starts ***\\n\")\n",
        "vectorizer = TfidfVectorizer()\n",
        "vec_x = vectorizer.fit_transform(data_text)\n",
        "\n",
        "grid = GridSearchCV(MultinomialNB(), param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001]}, scoring=\"accuracy\")\n",
        "grid.fit(vec_x, data_label)\n",
        "\n",
        "print(\"Best estimators:\", grid.best_estimator_)\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(\"Validation Score (Fine-Tuning):\", grid.best_score_)\n",
        "\n",
        "# Fine-Tuned NaiveBayes\n",
        "best_alpha = grid.best_params_[\"alpha\"]\n",
        "print(\"\\n*** Test Data Starts with Fine-Tune ***\\n\")\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB(alpha=best_alpha))\n",
        "\n",
        "model.fit(data_text, data_label)\n",
        "predictions = model.predict(test_data_text)\n",
        "\n",
        "accuracy_test_nb_fine_tuned = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "print(\"Classification Report for Naive Bayesian Fine-Tuned (Test):\")\n",
        "print(classification_report(test_data_label, predictions))\n",
        "\n",
        "\n",
        "print(\"\\n\\n*** Accuracy Results ***\")\n",
        "print(\"Accuracy Score for validation data:\", accuracy_validation_nb)\n",
        "print(\"Accuracy Score for test data:\", accuracy_test_nb)\n",
        "print(\"Accuracy Score for test data (fine-tuned):\", accuracy_test_nb_fine_tuned)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** Validation Data Starts ***\n",
            "\n",
            "Classification Report for Naive Bayesian (Validation):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.84      0.84       154\n",
            "        spor       0.90      0.97      0.93       151\n",
            "     turkiye       0.61      0.84      0.71       168\n",
            "       video       0.88      0.24      0.37       156\n",
            "    yazarlar       0.76      0.91      0.83       171\n",
            "\n",
            "    accuracy                           0.76       800\n",
            "   macro avg       0.79      0.76      0.74       800\n",
            "weighted avg       0.79      0.76      0.74       800\n",
            "\n",
            "\n",
            "*** Test Data Starts ***\n",
            "\n",
            "Classification Report for Naive Bayesian (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.79      0.86      0.82       395\n",
            "        spor       0.89      0.96      0.92       384\n",
            "     turkiye       0.58      0.77      0.66       421\n",
            "       video       0.91      0.21      0.34       408\n",
            "    yazarlar       0.75      0.95      0.84       392\n",
            "\n",
            "    accuracy                           0.75      2000\n",
            "   macro avg       0.78      0.75      0.72      2000\n",
            "weighted avg       0.78      0.75      0.71      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "Best estimators: MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
            "Best params: {'alpha': 0.01}\n",
            "Validation Score (Fine-Tuning): 0.789125\n",
            "\n",
            "*** Test Data Starts with Fine-Tune ***\n",
            "\n",
            "Classification Report for Naive Bayesian Fine-Tuned (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.84      0.83       395\n",
            "        spor       0.91      0.95      0.93       384\n",
            "     turkiye       0.64      0.67      0.66       421\n",
            "       video       0.76      0.47      0.58       408\n",
            "    yazarlar       0.76      0.96      0.85       392\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.78      0.78      0.77      2000\n",
            "weighted avg       0.78      0.78      0.77      2000\n",
            "\n",
            "\n",
            "\n",
            "*** Accuracy Results ***\n",
            "Accuracy Score for validation data: 0.76375\n",
            "Accuracy Score for test data: 0.7465\n",
            "Accuracy Score for test data (fine-tuned): 0.7765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fig_PpdOzBJN"
      },
      "source": [
        "# Logistic Regression Classifier TF-IDF NO Stopwords\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAfnoy4u0KLi",
        "outputId": "c2b90e03-39ca-461b-cc3e-7c9977f76caf"
      },
      "source": [
        "# Build the model\n",
        "model = make_pipeline(TfidfVectorizer(), LogisticRegression())\n",
        "\n",
        "# Fit the Train Data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n*** Validation Data Starts ***\\n\")\n",
        "\n",
        "# Predict the Validation Data\n",
        "predictions = model.predict(X_valid)\n",
        "\n",
        "# Accuracy of the Logistic Regression for validation\n",
        "accuracy_validation_logres = accuracy_score(y_valid, predictions)\n",
        "\n",
        "print(\"Classification Report for Logistic Regression (Validation):\")\n",
        "print(classification_report(y_valid, predictions))\n",
        "\n",
        "# Accuracy of the Logistic Regression for test\n",
        "print(\"\\n*** Test Data Starts ***\\n\")\n",
        "model.fit(data_text, data_label)\n",
        "\n",
        "predictions = model.predict(test_data_text)\n",
        "\n",
        "accuracy_test_logres = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "print(\"Classification Report for Logistic Regression (Test):\")\n",
        "print(classification_report(test_data_label, predictions))\n",
        "\n",
        "# # Accuract with Fine-Tuning (GridSearchCV)\n",
        "# print(\"\\n*** GridSearchCV Starts ***\\n\")\n",
        "# vectorizer = TfidfVectorizer()\n",
        "# vec_x = vectorizer.fit_transform(data_text)\n",
        "\n",
        "# # solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}\n",
        "# # c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "# parameters = {\n",
        "#     \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
        "#     \"C\": [100, 10, 1.0, 0.1, 0.01],\n",
        "# }\n",
        "\n",
        "# grid = GridSearchCV(LogisticRegression(max_iter=200), param_grid=parameters, scoring=\"accuracy\")\n",
        "# grid.fit(vec_x, data_label)\n",
        "\n",
        "# print(\"Best estimators:\", grid.best_estimator_)\n",
        "# print(\"Best params:\", grid.best_params_)\n",
        "# print(\"Validation Score (Fine-Tuning):\", grid.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** Validation Data Starts ***\n",
            "\n",
            "Classification Report for Logistic Regression (Validation):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.84      0.84      0.84       154\n",
            "        spor       0.91      0.94      0.93       151\n",
            "     turkiye       0.78      0.76      0.77       168\n",
            "       video       0.80      0.78      0.79       156\n",
            "    yazarlar       0.88      0.92      0.90       171\n",
            "\n",
            "    accuracy                           0.84       800\n",
            "   macro avg       0.84      0.85      0.84       800\n",
            "weighted avg       0.84      0.84      0.84       800\n",
            "\n",
            "\n",
            "*** Test Data Starts ***\n",
            "\n",
            "Classification Report for Logistic Regression (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.86      0.84       395\n",
            "        spor       0.94      0.94      0.94       384\n",
            "     turkiye       0.78      0.68      0.73       421\n",
            "       video       0.77      0.78      0.78       408\n",
            "    yazarlar       0.87      0.94      0.91       392\n",
            "\n",
            "    accuracy                           0.84      2000\n",
            "   macro avg       0.84      0.84      0.84      2000\n",
            "weighted avg       0.83      0.84      0.83      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mj-Yf4T0NWN"
      },
      "source": [
        "# Logistic Regression Classifier TF-IDF with Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frbZohe-y_6k",
        "outputId": "fb87d760-8249-4fc5-e13c-81339ed1613c"
      },
      "source": [
        "# Build the model\r\n",
        "model = make_pipeline(TfidfVectorizer(stop_words=stopWords), LogisticRegression(max_iter=200))\r\n",
        "\r\n",
        "# Fit the Train Data\r\n",
        "model.fit(X_train, y_train)\r\n",
        "\r\n",
        "print(\"\\n*** Validation Data Starts ***\\n\")\r\n",
        "\r\n",
        "# Predict the Validation Data\r\n",
        "predictions = model.predict(X_valid)\r\n",
        "\r\n",
        "# Accuracy of the Logistic Regression for validation\r\n",
        "accuracy_validation_logres = accuracy_score(y_valid, predictions)\r\n",
        "\r\n",
        "print(\"Classification Report for Logistic Regression (Validation):\")\r\n",
        "print(classification_report(y_valid, predictions))\r\n",
        "\r\n",
        "# Accuracy of the Logistic Regression for test\r\n",
        "print(\"\\n*** Test Data Starts ***\\n\")\r\n",
        "model.fit(data_text, data_label)\r\n",
        "\r\n",
        "predictions = model.predict(test_data_text)\r\n",
        "\r\n",
        "accuracy_test_logres = accuracy_score(test_data_label, predictions)\r\n",
        "\r\n",
        "print(\"Classification Report for Logistic Regression (Test):\")\r\n",
        "print(classification_report(test_data_label, predictions))\r\n",
        "\r\n",
        "# # Accuract with Fine-Tuning (GridSearchCV)\r\n",
        "# print(\"\\n*** GridSearchCV Starts ***\\n\")\r\n",
        "# vectorizer = TfidfVectorizer()\r\n",
        "# vec_x = vectorizer.fit_transform(data_text)\r\n",
        "\r\n",
        "# # solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}\r\n",
        "# # c_values = [100, 10, 1.0, 0.1, 0.01]\r\n",
        "\r\n",
        "# parameters = {\r\n",
        "#     \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\r\n",
        "#     \"C\": [100, 10, 1.0, 0.1, 0.01],\r\n",
        "# }\r\n",
        "\r\n",
        "# grid = GridSearchCV(LogisticRegression(max_iter=200), param_grid=parameters, scoring=\"accuracy\")\r\n",
        "# grid.fit(vec_x, data_label)\r\n",
        "\r\n",
        "# print(\"Best estimators:\", grid.best_estimator_)\r\n",
        "# print(\"Best params:\", grid.best_params_)\r\n",
        "# print(\"Validation Score (Fine-Tuning):\", grid.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** Validation Data Starts ***\n",
            "\n",
            "Classification Report for Logistic Regression (Validation):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.83      0.83       154\n",
            "        spor       0.91      0.95      0.93       151\n",
            "     turkiye       0.75      0.72      0.73       168\n",
            "       video       0.76      0.74      0.75       156\n",
            "    yazarlar       0.89      0.89      0.89       171\n",
            "\n",
            "    accuracy                           0.83       800\n",
            "   macro avg       0.82      0.83      0.83       800\n",
            "weighted avg       0.82      0.83      0.83       800\n",
            "\n",
            "\n",
            "*** Test Data Starts ***\n",
            "\n",
            "Classification Report for Logistic Regression (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.87      0.84       395\n",
            "        spor       0.93      0.93      0.93       384\n",
            "     turkiye       0.77      0.69      0.73       421\n",
            "       video       0.78      0.76      0.77       408\n",
            "    yazarlar       0.86      0.92      0.89       392\n",
            "\n",
            "    accuracy                           0.83      2000\n",
            "   macro avg       0.83      0.84      0.83      2000\n",
            "weighted avg       0.83      0.83      0.83      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orI6OptN1IFT"
      },
      "source": [
        "# Logistic Regression Classifier TF NO Stopword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5Nd6YxZ1QKw",
        "outputId": "b8c7ea81-ce9a-4301-a8ec-2a3d00762c71"
      },
      "source": [
        "# Build the model\n",
        "model = make_pipeline(CountVectorizer(), LogisticRegression(max_iter=400))\n",
        "\n",
        "# Fit the Train Data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n*** Validation Data Starts ***\\n\")\n",
        "\n",
        "# Predict the Validation Data\n",
        "predictions = model.predict(X_valid)\n",
        "\n",
        "# Accuracy of the Logistic Regression for validation\n",
        "accuracy_validation_logres = accuracy_score(y_valid, predictions)\n",
        "\n",
        "print(\"Classification Report for Logistic Regression (Validation):\")\n",
        "print(classification_report(y_valid, predictions))\n",
        "\n",
        "# Accuracy of the Logistic Regression for test\n",
        "print(\"\\n*** Test Data Starts ***\\n\")\n",
        "model.fit(data_text, data_label)\n",
        "\n",
        "predictions = model.predict(test_data_text)\n",
        "\n",
        "accuracy_test_logres = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "print(\"Classification Report for Logistic Regression (Test):\")\n",
        "print(classification_report(test_data_label, predictions))\n",
        "\n",
        "# # Accuract with Fine-Tuning (GridSearchCV)\n",
        "# print(\"\\n*** GridSearchCV Starts ***\\n\")\n",
        "# vectorizer = TfidfVectorizer()\n",
        "# vec_x = vectorizer.fit_transform(data_text)\n",
        "\n",
        "# # solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}\n",
        "# # c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "# parameters = {\n",
        "#     \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
        "#     \"C\": [100, 10, 1.0, 0.1, 0.01],\n",
        "# }\n",
        "\n",
        "# grid = GridSearchCV(LogisticRegression(max_iter=200), param_grid=parameters, scoring=\"accuracy\")\n",
        "# grid.fit(vec_x, data_label)\n",
        "\n",
        "# print(\"Best estimators:\", grid.best_estimator_)\n",
        "# print(\"Best params:\", grid.best_params_)\n",
        "# print(\"Validation Score (Fine-Tuning):\", grid.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** Validation Data Starts ***\n",
            "\n",
            "Classification Report for Logistic Regression (Validation):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.86      0.81      0.83       154\n",
            "        spor       0.93      0.93      0.93       151\n",
            "     turkiye       0.79      0.76      0.77       168\n",
            "       video       0.77      0.86      0.81       156\n",
            "    yazarlar       0.93      0.92      0.93       171\n",
            "\n",
            "    accuracy                           0.86       800\n",
            "   macro avg       0.86      0.86      0.86       800\n",
            "weighted avg       0.86      0.86      0.86       800\n",
            "\n",
            "\n",
            "*** Test Data Starts ***\n",
            "\n",
            "Classification Report for Logistic Regression (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.84      0.84       395\n",
            "        spor       0.94      0.90      0.92       384\n",
            "     turkiye       0.80      0.69      0.74       421\n",
            "       video       0.75      0.88      0.81       408\n",
            "    yazarlar       0.91      0.92      0.91       392\n",
            "\n",
            "    accuracy                           0.84      2000\n",
            "   macro avg       0.85      0.85      0.84      2000\n",
            "weighted avg       0.85      0.84      0.84      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GVGa-YG1Vvx"
      },
      "source": [
        "# Logistic Regression Classifier TF With Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhNp6ZA11b7p",
        "outputId": "4e7af089-c5ed-4d19-bf12-5f70f79c1cfa"
      },
      "source": [
        "# Build the model\n",
        "model = make_pipeline(CountVectorizer(stop_words=stopWords), LogisticRegression(max_iter=1000))\n",
        "\n",
        "# Fit the Train Data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n*** Validation Data Starts ***\\n\")\n",
        "\n",
        "# Predict the Validation Data\n",
        "predictions = model.predict(X_valid)\n",
        "\n",
        "# Accuracy of the Logistic Regression for validation\n",
        "accuracy_validation_logres = accuracy_score(y_valid, predictions)\n",
        "\n",
        "print(\"Classification Report for Logistic Regression (Validation):\")\n",
        "print(classification_report(y_valid, predictions))\n",
        "\n",
        "# Accuracy of the Logistic Regression for test\n",
        "print(\"\\n*** Test Data Starts ***\\n\")\n",
        "model.fit(data_text, data_label)\n",
        "\n",
        "predictions = model.predict(test_data_text)\n",
        "\n",
        "accuracy_test_logres = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "print(\"Classification Report for Logistic Regression (Test):\")\n",
        "print(classification_report(test_data_label, predictions))\n",
        "\n",
        "# Accuract with Fine-Tuning (GridSearchCV)\n",
        "print(\"\\n*** GridSearchCV Starts ***\\n\")\n",
        "vectorizer = CountVectorizer()\n",
        "vec_x = vectorizer.fit_transform(data_text)\n",
        "\n",
        "# solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}\n",
        "# c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "parameters = {\n",
        "    \"C\": [100, 10, 1.0, 0.1, 0.01],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid=parameters, scoring=\"accuracy\")\n",
        "grid.fit(vec_x, data_label)\n",
        "\n",
        "print(\"Best estimators:\", grid.best_estimator_)\n",
        "print(\"Best params:\", grid.best_params_)\n",
        "print(\"Validation Score (Fine-Tuning):\", grid.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** Validation Data Starts ***\n",
            "\n",
            "Classification Report for Logistic Regression (Validation):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.85      0.79      0.82       154\n",
            "        spor       0.94      0.95      0.95       151\n",
            "     turkiye       0.78      0.74      0.76       168\n",
            "       video       0.77      0.85      0.80       156\n",
            "    yazarlar       0.91      0.91      0.91       171\n",
            "\n",
            "    accuracy                           0.85       800\n",
            "   macro avg       0.85      0.85      0.85       800\n",
            "weighted avg       0.85      0.85      0.85       800\n",
            "\n",
            "\n",
            "*** Test Data Starts ***\n",
            "\n",
            "Classification Report for Logistic Regression (Test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.83      0.84      0.84       395\n",
            "        spor       0.94      0.92      0.93       384\n",
            "     turkiye       0.82      0.68      0.75       421\n",
            "       video       0.75      0.88      0.81       408\n",
            "    yazarlar       0.92      0.92      0.92       392\n",
            "\n",
            "    accuracy                           0.85      2000\n",
            "   macro avg       0.85      0.85      0.85      2000\n",
            "weighted avg       0.85      0.85      0.85      2000\n",
            "\n",
            "\n",
            "*** GridSearchCV Starts ***\n",
            "\n",
            "Best estimators: LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "Best params: {'C': 0.1}\n",
            "Validation Score (Fine-Tuning): 0.842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5up6XU6LCIAv",
        "outputId": "4c7a24e9-9716-4f29-8ece-d055a4c05e5a"
      },
      "source": [
        "# Build the model\n",
        "model = make_pipeline(CountVectorizer(stop_words=stopWords), LogisticRegression(max_iter=1000, C=0.1))\n",
        "\n",
        "# Fit the Train Data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n*** Validation Data Starts ***\\n\")\n",
        "\n",
        "# Predict the Validation Data\n",
        "predictions = model.predict(X_valid)\n",
        "\n",
        "# Accuracy of the Logistic Regression for validation\n",
        "accuracy_validation_logres = accuracy_score(y_valid, predictions)\n",
        "\n",
        "print(\"Classification Report for Logistic Regression (Validation):\")\n",
        "print(classification_report(y_valid, predictions))\n",
        "\n",
        "# Accuracy of the Logistic Regression for test\n",
        "print(\"\\n*** Test Data Starts ***\\n\")\n",
        "model.fit(data_text, data_label)\n",
        "\n",
        "predictions = model.predict(test_data_text)\n",
        "\n",
        "accuracy_test_logres = accuracy_score(test_data_label, predictions)\n",
        "\n",
        "print(\"Classification Report for Logistic Regression (Test):\")\n",
        "print(classification_report(test_data_label, predictions))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*** Validation Data Starts ***\n",
            "\n",
            "Classification Report for Logistic Regression (Validation):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.85      0.81      0.83       154\n",
            "        spor       0.94      0.95      0.94       151\n",
            "     turkiye       0.79      0.76      0.77       168\n",
            "       video       0.76      0.84      0.80       156\n",
            "    yazarlar       0.93      0.91      0.92       171\n",
            "\n",
            "    accuracy                           0.85       800\n",
            "   macro avg       0.85      0.85      0.85       800\n",
            "weighted avg       0.85      0.85      0.85       800\n",
            "\n",
            "\n",
            "*** Test Data Starts ***\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfK4RxMfKRqP"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RJFnoKvKVqv"
      },
      "source": [
        "# Build the model\r\n",
        "model = make_pipeline(TfidfVectorizer(), LogisticRegression())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX7Qs0BYK-Vq",
        "outputId": "87453246-4e85-4447-b53f-8debdf65b8af"
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidfvectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('logisticregression',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBKs_kAQLE_2"
      },
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBdYiKX0LJLv",
        "outputId": "5d811416-0c22-4d1e-8ea7-8c5c513de6aa"
      },
      "source": [
        "accuracy_score(y_test, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.845"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w18jr0_4LMTy",
        "outputId": "b0b97646-f151-4fe8-f120-a52436e0158d"
      },
      "source": [
        "print(\"Classification Report for Logistic Regression:\")\r\n",
        "print(classification_report(y_test, predictions)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.84      0.84      0.84       154\n",
            "        spor       0.91      0.94      0.93       151\n",
            "     turkiye       0.78      0.76      0.77       168\n",
            "       video       0.80      0.78      0.79       156\n",
            "    yazarlar       0.88      0.92      0.90       171\n",
            "\n",
            "    accuracy                           0.84       800\n",
            "   macro avg       0.84      0.85      0.84       800\n",
            "weighted avg       0.84      0.84      0.84       800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z81-xBBZLTu1"
      },
      "source": [
        "predictions = model.predict(test_data_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7SXbOxWLV9V",
        "outputId": "42742671-7cbd-45a7-93e3-4b2b3ed666ff"
      },
      "source": [
        "accuracy_score(test_data_label, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8325"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eZ-jjeSLX8z",
        "outputId": "f18df5e0-f05a-4c94-d780-906cf60d1394"
      },
      "source": [
        "print(\"Classification Report for Logistic Regression:\")\r\n",
        "print(classification_report(test_data_label, predictions)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.86      0.84       395\n",
            "        spor       0.94      0.93      0.94       384\n",
            "     turkiye       0.77      0.67      0.72       421\n",
            "       video       0.77      0.78      0.77       408\n",
            "    yazarlar       0.86      0.94      0.90       392\n",
            "\n",
            "    accuracy                           0.83      2000\n",
            "   macro avg       0.83      0.84      0.83      2000\n",
            "weighted avg       0.83      0.83      0.83      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NTfIpdbllvF"
      },
      "source": [
        "# GridSearch for Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBzBIrYyl9wr",
        "outputId": "c3448805-e641-482c-b1bd-d78197085856"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\r\n",
        "vec_x = vectorizer.fit_transform(X_train)\r\n",
        "\r\n",
        "params = {\r\n",
        "    \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\r\n",
        "    \"C\": np.logspace(-3,3,7),\r\n",
        "}\r\n",
        "\r\n",
        "# solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’\r\n",
        "\r\n",
        "\r\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid=params, scoring=\"accuracy\")\r\n",
        "grid.fit(vec_x, y_train)\r\n",
        "print(grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=None, error_score=nan,\n",
            "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
            "                                          fit_intercept=True,\n",
            "                                          intercept_scaling=1, l1_ratio=None,\n",
            "                                          max_iter=100, multi_class='auto',\n",
            "                                          n_jobs=None, penalty='l2',\n",
            "                                          random_state=None, solver='lbfgs',\n",
            "                                          tol=0.0001, verbose=0,\n",
            "                                          warm_start=False),\n",
            "             iid='deprecated', n_jobs=None,\n",
            "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
            "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
            "                                    'saga']},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring='accuracy', verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlT0VDixmlm2",
        "outputId": "78c83685-0d84-4aa3-bff7-2f685f06c331"
      },
      "source": [
        "grid.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2khz_rgAmm_u",
        "outputId": "4ab1a438-7905-4fb9-9808-80a8dd446a50"
      },
      "source": [
        "grid.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 10.0, 'solver': 'liblinear'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyT-ubxrmoU9",
        "outputId": "7084573c-3a40-4127-e633-02ab03549879"
      },
      "source": [
        "grid.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8368055555555556"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtGbFXmDxjkW"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4IP0jJwEZ21"
      },
      "source": [
        "# Build the model\r\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK0sXyo3EgNX",
        "outputId": "cc9cee89-3170-41d8-831d-2ebc28c2e460"
      },
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidfvectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('multinomialnb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAHzjALiGQUg"
      },
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUMau0fiGUxP",
        "outputId": "bed8eebf-a9b0-4a06-b304-92933f18d64a"
      },
      "source": [
        "accuracy_score(y_test, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7275"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIzVa34RJk5f",
        "outputId": "2db394c7-282b-400d-f0cc-0e1fc24d1301"
      },
      "source": [
        "print(\"Classification Report for Naive Bayesian:\")\r\n",
        "print(classification_report(y_test, predictions)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for Naive Bayesian:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.84      0.73      0.78       154\n",
            "        spor       0.88      0.95      0.91       151\n",
            "     turkiye       0.65      0.73      0.69       168\n",
            "       video       0.95      0.27      0.42       156\n",
            "    yazarlar       0.60      0.95      0.73       171\n",
            "\n",
            "    accuracy                           0.73       800\n",
            "   macro avg       0.78      0.72      0.71       800\n",
            "weighted avg       0.78      0.73      0.71       800\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjg6M9-hG7X4"
      },
      "source": [
        "predictions = model.predict(test_data_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "He_3REYNG-p-",
        "outputId": "cc54301a-2f90-4c1d-8ac2-35bec9198cae"
      },
      "source": [
        "accuracy_score(test_data_label, predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7035"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS9pzVvdHFop",
        "outputId": "ea8a3641-12c8-4141-c3fb-6faf9c244847"
      },
      "source": [
        "print(\"Classification Report for Naive Bayesian:\")\r\n",
        "print(classification_report(test_data_label, predictions)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for Naive Bayesian:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.80      0.77      0.78       395\n",
            "        spor       0.89      0.94      0.92       384\n",
            "     turkiye       0.59      0.67      0.62       421\n",
            "       video       0.95      0.19      0.32       408\n",
            "    yazarlar       0.58      0.98      0.73       392\n",
            "\n",
            "    accuracy                           0.70      2000\n",
            "   macro avg       0.76      0.71      0.68      2000\n",
            "weighted avg       0.76      0.70      0.67      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3igcp1czM3oY"
      },
      "source": [
        "# GridSearch for Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mOhyPN5M2di",
        "outputId": "acf523f8-82ed-402e-92dc-2a1d427e76e9"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\r\n",
        "vec_x = vectorizer.fit_transform(X_train)\r\n",
        "\r\n",
        "grid = GridSearchCV(MultinomialNB(), param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001]}, scoring=\"accuracy\")\r\n",
        "grid.fit(vec_x, y_train)\r\n",
        "print(grid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GridSearchCV(cv=None, error_score=nan,\n",
            "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
            "                                     fit_prior=True),\n",
            "             iid='deprecated', n_jobs=None,\n",
            "             param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring='accuracy', verbose=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hfxpDNcTCbQ",
        "outputId": "6bde94d3-ef97-4e35-afa3-b3635921169a"
      },
      "source": [
        "grid.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEFdtFBPW5F5",
        "outputId": "0e6ff0b5-e579-468c-af79-3bad6f031f25"
      },
      "source": [
        "grid.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.01}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ENzcb81trNV",
        "outputId": "fc10dc56-02f4-4a16-d34a-6bb93b4d2825"
      },
      "source": [
        "grid.best_score_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7848611111111111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLiW8GHwt1I6"
      },
      "source": [
        "# Build the model\r\n",
        "model = make_pipeline(TfidfVectorizer(), MultinomialNB(alpha=0.01))\r\n",
        "\r\n",
        "model.fit(data_text, data_label)\r\n",
        "predictions = model.predict(test_data_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJTrU7rsuBgS",
        "outputId": "db642916-a049-4547-9a47-eb61fd0f5a5d"
      },
      "source": [
        "print(\"Classification Report for Naive Bayesian:\")\r\n",
        "print(classification_report(test_data_label, predictions)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification Report for Naive Bayesian:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       dunya       0.82      0.84      0.83       395\n",
            "        spor       0.91      0.95      0.93       384\n",
            "     turkiye       0.64      0.67      0.66       421\n",
            "       video       0.76      0.47      0.58       408\n",
            "    yazarlar       0.76      0.96      0.85       392\n",
            "\n",
            "    accuracy                           0.78      2000\n",
            "   macro avg       0.78      0.78      0.77      2000\n",
            "weighted avg       0.78      0.78      0.77      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}