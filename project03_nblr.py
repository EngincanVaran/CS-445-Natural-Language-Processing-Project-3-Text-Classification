# -*- coding: utf-8 -*-
"""project03_NBLR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UJiSGvMSuWohPgZC0lZlH95NoIYgvk4N
"""

import nltk
nltk.download("stopwords")
nltk.download('punkt')

import pandas as pd
import numpy as np
import re
import seaborn as sns
import matplotlib.pyplot as plt
from nltk.corpus import stopwords as STOPWORDS
from nltk import word_tokenize, sent_tokenize
stopWords = set(STOPWORDS.words('turkish'))

from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV

def preprocess(docs):
    result = []
    for d in docs:
        a = re.sub(r'[\'’\"”][\w]+ ', " " ,d)
        for stopword in stopWords:
            a = a.replace(" "+ stopword + " ", " ")
        a = re.sub(r'[“’‘\'\"”…]', "", a)
        a = re.sub(r'\d+', "", a)
        a = a.replace("  ", " ")
        result.append(a.lower())
    return result

def read_data(path):
    data = pd.read_csv(path)
    return data

path = "/content/drive/MyDrive/CS 445 Project 3/dataset/train.csv"
data = read_data(path)

path = "/content/drive/MyDrive/CS 445 Project 3/dataset/test.csv"
test_data = read_data(path)

data_text = data["text"]
data_label = data["label"]

test_data_text = test_data["text"]
test_data_label = test_data["label"]

data_text[0]

data_text_processed = preprocess(data_text)
test_data_text_processed = preprocess(test_data_text)

data_text_processed[0]

class_mapping = {
    "turkiye": 0,
    "dunya": 1,
    "spor": 2,
    "video": 3,
    "yazarlar": 4,
}

counts = {
    "turkiye": 0,
    "dunya": 0,
    "spor": 0,
    "video": 0,
    "yazarlar": 0, 
}

for label in data_label:
    counts[label] += 1

print(counts)

counts = {
    "turkiye": 0,
    "dunya": 0,
    "spor": 0,
    "video": 0,
    "yazarlar": 0, 
}

for label in test_data_label:
    counts[label] += 1

print(counts)

X_train, X_valid, y_train, y_valid = train_test_split(data_text, data_label, test_size=0.1, random_state=1)

vectorizerList = ["TF", "TF-IDF"]
includeStopWordsList = [ "yes", "no" ]

def loopAllForNB(data_text, data_label, test_data_text, test_data_label, data_type):

    outFile = open("/content/drive/MyDrive/CS 445 Project 3/Naive Bayes_" + data_type + ".txt", "w")

    test_results = {}

    for includeStopWords in includeStopWordsList:
        for vectorizerType in vectorizerList:
            if includeStopWords == "yes" and vectorizerType == "TF":
                vectorizer = CountVectorizer()
            
            elif includeStopWords == "yes" and vectorizerType == "TF-IDF":
                vectorizer = TfidfVectorizer()
            
            elif includeStopWords == "no" and vectorizerType == "TF":
                vectorizer = CountVectorizer(stop_words=stopWords)
            
            elif includeStopWords == "no" and vectorizerType == "TF-IDF":
                vectorizer = TfidfVectorizer(stop_words=stopWords)

            else:
                print("What are doing here???")
                return

            X_train, X_valid, y_train, y_valid = train_test_split(data_text, data_label, test_size=0.1, random_state=1)

            title = "Vectorizer Type: " + vectorizerType + "\tInclude Stopwords: " + includeStopWords + "\tData Type: " + data_type
            
            outFile.write("*** Start For " + title + " ***\n")

            model = make_pipeline(vectorizer, MultinomialNB())

            print("Fitting data:", title)
            model.fit(X_train, y_train)

            # Predict the Validation Data
            predictions = model.predict(X_valid)

            # Accuracy of the Naive Bayes for validation
            accuracy_validation_nb = accuracy_score(y_valid, predictions)

            print("Classification Report for Naive Bayesian (Validation) -->", title)
            print(classification_report(y_valid, predictions))
            
            outFile.write("Classification Report for Naive Bayesian (Validation) --> " + title + "\n")
            outFile.write(classification_report(y_valid, predictions))
            outFile.write("\n\n\n")

            # Accuracy of the Naive Bayes for test
            model.fit(data_text, data_label)

            predictions = model.predict(test_data_text)

            accuracy_test_nb = accuracy_score(test_data_label, predictions)

            print("Classification Report for Naive Bayesian (Test) -->", title)
            print(classification_report(test_data_label, predictions))

            outFile.write("Classification Report for Naive Bayesian (Test) --> " + title + "\n")
            outFile.write(classification_report(test_data_label, predictions))
            outFile.write("\n\n\n")

            # Accuracy with Fine-Tuning (GridSearchCV)
            print("\n*** GridSearchCV Starts ***\n")
            vec_x = vectorizer.fit_transform(data_text)

            grid = GridSearchCV(MultinomialNB(), param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001]}, scoring="accuracy")
            grid.fit(vec_x, data_label)

            print("\t\tBest estimators:", grid.best_estimator_)
            print("\t\tBest params:", grid.best_params_)
            print("\t\tValidation Score (Fine-Tuning):", grid.best_score_)

            # Fine-Tuned NaiveBayes
            best_alpha = grid.best_params_["alpha"]
            print("\n*** Test Data Starts with Fine-Tune ***\n")
            model = make_pipeline(vectorizer, MultinomialNB(alpha=best_alpha))

            model.fit(data_text, data_label)
            predictions = model.predict(test_data_text)

            accuracy_test_nb_fine_tuned = accuracy_score(test_data_label, predictions)

            print("Classification Report for Naive Bayesian Fine-Tuned (Test) -->", title)
            print(classification_report(test_data_label, predictions))

            outFile.write("Classification Report for Naive Bayesian Fine-Tuned (Test) --> " + title + "\n")
            outFile.write(classification_report(test_data_label, predictions))
            outFile.write("\n\n")


            print("\n\n*** Accuracy Results ***")
            print("Accuracy Score for validation data:", accuracy_validation_nb)
            print("Accuracy Score for test data:", accuracy_test_nb)
            print("Accuracy Score for test data (fine-tuned):", accuracy_test_nb_fine_tuned, "\n\n\n")

            test_results[title] = accuracy_test_nb
            test_results[title+"(fineTuned)"] = accuracy_test_nb_fine_tuned

            outFile.write("\n\n*** Accuracy Results ***\n")
            outFile.write("Accuracy Score for validation data: " + str(accuracy_validation_nb) + "\n" )
            outFile.write("Accuracy Score for test data: " + str(accuracy_test_nb) + "\n" )
            outFile.write("Accuracy Score for test data (fine-tuned): " + str(accuracy_test_nb_fine_tuned) + "\n\n\n" )
            
            outFile.write("*** End For " + title + " ***\n\n\n")

    print("*** Final Results ***")
    outFile.write("*** Final Results ***\n")
    for key, value in test_results.items():
        print(key, " -->\t", value)
        outFile.write( key + " :\t" + str(value) + "\n" )

    outFile.close()

loopAllForNB(data_text, data_label, test_data_text, test_data_label, "normal")

loopAllForNB(data_text_processed, data_label, test_data_text_processed, test_data_label, "preprocessed")

# *** Final Results ***
# Vectorizer Type: TF	Include Stopwords: yes	Data Type: normal  -->  0.742
# Vectorizer Type: TF	Include Stopwords: yes	Data Type: normal(fineTuned)  -->  0.781
# Vectorizer Type: TF-IDF	Include Stopwords: yes	Data Type: normal  -->  0.7055
# Vectorizer Type: TF-IDF	Include Stopwords: yes	Data Type: normal(fineTuned)  -->  0.7765
# Vectorizer Type: TF	Include Stopwords: no	Data Type: normal  -->  0.7465
# Vectorizer Type: TF	Include Stopwords: no	Data Type: normal(fineTuned)  -->  0.7795
# Vectorizer Type: TF-IDF	Include Stopwords: no	Data Type: normal  -->  0.717
# Vectorizer Type: TF-IDF	Include Stopwords: no	Data Type: normal(fineTuned)  -->  0.7755

vectorizerList = ["TF", "TF-IDF"]
includeStopWordsList = [ "yes", "no" ]

def loopAllforLogres(data_text, data_label, test_data_text, test_data_label, data_type):

    outFile = open("/content/drive/MyDrive/CS 445 Project 3/Logistic Regression_" + data_type + ".txt", "w")

    iterLimit = 400

    test_results = {}

    for includeStopWords in includeStopWordsList:
        for vectorizerType in vectorizerList:
            if includeStopWords == "yes" and vectorizerType == "TF":
                vectorizer = CountVectorizer()
            
            elif includeStopWords == "yes" and vectorizerType == "TF-IDF":
                vectorizer = TfidfVectorizer()
            
            elif includeStopWords == "no" and vectorizerType == "TF":
                vectorizer = CountVectorizer(stop_words=stopWords)
            
            elif includeStopWords == "no" and vectorizerType == "TF-IDF":
                vectorizer = TfidfVectorizer(stop_words=stopWords)

            else:
                print("What are doing here???")
                return

            X_train, X_valid, y_train, y_valid = train_test_split(data_text, data_label, test_size=0.1, random_state=1)

            title = "Vectorizer Type: " + vectorizerType + "\tInclude Stopwords: " + includeStopWords + "\tData Type: " + data_type
            
            outFile.write("*** Start For " + title + " ***\n")

            model = make_pipeline(vectorizer, LogisticRegression(max_iter=iterLimit, random_state=42))

            print("Fitting data:", title)
            model.fit(X_train, y_train)

            # Predict the Validation Data
            predictions = model.predict(X_valid)

            # Accuracy of the Naive Bayes for validation
            accuracy_validation_logres = accuracy_score(y_valid, predictions)

            print("Classification Report for Logistic Regression (Validation) -->", title)
            print(classification_report(y_valid, predictions))
            
            outFile.write("Classification Report for Logistic Regression (Validation) --> " + title + "\n")
            outFile.write(classification_report(y_valid, predictions))
            outFile.write("\n\n\n")

            # Accuracy of the Naive Bayes for test
            model.fit(data_text, data_label)

            predictions = model.predict(test_data_text)

            accuracy_test_logres = accuracy_score(test_data_label, predictions)

            print("Classification Report for Logistic Regression (Test) -->", title)
            print(classification_report(test_data_label, predictions))

            outFile.write("Classification Report for Logistic Regression (Test) --> " + title + "\n")
            outFile.write(classification_report(test_data_label, predictions))
            outFile.write("\n\n\n")

            # Accuracy with Fine-Tuning (GridSearchCV)
            print("\n*** GridSearchCV Starts ***\n")
            vec_x = vectorizer.fit_transform(data_text)

            grid = GridSearchCV(LogisticRegression(max_iter=iterLimit, random_state=42), param_grid={'C': [0.001,0.01,0.1,1,10,100]}, scoring="accuracy")
            grid.fit(vec_x, data_label)

            print("\t\tBest estimators:", grid.best_estimator_)
            print("\t\tBest params:", grid.best_params_)
            print("\t\tValidation Score (Fine-Tuning):", grid.best_score_)

            # Fine-Tuned NaiveBayes
            best_C = grid.best_params_["C"]
            print("\n*** Test Data Starts with Fine-Tune ***\n")
            model = make_pipeline(vectorizer, LogisticRegression(C=best_C, max_iter=iterLimit, random_state=42))

            model.fit(data_text, data_label)
            predictions = model.predict(test_data_text)

            accuracy_test_logres_fine_tuned = accuracy_score(test_data_label, predictions)

            print("Classification Report for Logistic Regression Fine-Tuned (Test) -->", title)
            print(classification_report(test_data_label, predictions))

            outFile.write("Classification Report for Logistic Regression Fine-Tuned (Test) --> " + title + "\n")
            outFile.write(classification_report(test_data_label, predictions))
            outFile.write("\n\n")


            print("\n\n*** Accuracy Results ***")
            print("Accuracy Score for validation data:", accuracy_validation_logres)
            print("Accuracy Score for test data:", accuracy_test_logres)
            print("Accuracy Score for test data (fine-tuned):", accuracy_test_logres_fine_tuned, "\n\n\n")

            test_results[title] = accuracy_test_logres
            test_results[title+"(fineTuned)"] = accuracy_test_logres_fine_tuned

            outFile.write("\n\n*** Accuracy Results ***\n")
            outFile.write("Accuracy Score for validation data: " + str(accuracy_validation_logres) + "\n" )
            outFile.write("Accuracy Score for test data: " + str(accuracy_test_logres) + "\n" )
            outFile.write("Accuracy Score for test data (fine-tuned): " + str(accuracy_test_logres_fine_tuned) + "\n\n\n" )
            
            outFile.write("*** End For " + title + " ***\n\n\n")

    print("*** Final Results ***")
    outFile.write("*** Final Results ***\n")
    for key, value in test_results.items():
        print(key, " -->\t", value)
        outFile.write( key + " :\t" + str(value) + "\n" )

    outFile.close()

loopAllforLogres(data_text, data_label, test_data_text, test_data_label, "normal")

loopAllforLogres(data_text, data_label, test_data_text, test_data_label, "preprocessed")

"""# Naive Bayes Classifier with TF-IDF Vectorizer No Stopwords

"""

# Build the model
model = make_pipeline(TfidfVectorizer(), MultinomialNB())

# Fit the Train Data
model.fit(X_train, y_train)

print("\n*** Validation Data Starts ***\n")

# Predict the Validation Data
predictions = model.predict(X_valid)

# Accuracy of the Naive Bayes for validation
accuracy_validation_nb = accuracy_score(y_valid, predictions)

print("Classification Report for Naive Bayesian (Validation):")
print(classification_report(y_valid, predictions))

# Accuracy of the Naive Bayes for test
print("\n*** Test Data Starts ***\n")
model.fit(data_text, data_label)

predictions = model.predict(test_data_text)

accuracy_test_nb = accuracy_score(test_data_label, predictions)

print("Classification Report for Naive Bayesian (Test):")
print(classification_report(test_data_label, predictions))

# Accuract with Fine-Tuning (GridSearchCV)
print("\n*** GridSearchCV Starts ***\n")
vectorizer = TfidfVectorizer()
vec_x = vectorizer.fit_transform(data_text)

grid = GridSearchCV(MultinomialNB(), param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001]}, scoring="accuracy")
grid.fit(vec_x, data_label)

print("Best estimators:", grid.best_estimator_)
print("Best params:", grid.best_params_)
print("Validation Score (Fine-Tuning):", grid.best_score_)

# Fine-Tuned NaiveBayes
best_alpha = grid.best_params_["alpha"]
print("\n*** Test Data Starts with Fine-Tune ***\n")
model = make_pipeline(TfidfVectorizer(), MultinomialNB(alpha=best_alpha))

model.fit(data_text, data_label)
predictions = model.predict(test_data_text)

accuracy_test_nb_fine_tuned = accuracy_score(test_data_label, predictions)

print("Classification Report for Naive Bayesian Fine-Tuned (Test):")
print(classification_report(test_data_label, predictions))


print("\n\n*** Accuracy Results ***")
print("Accuracy Score for validation data:", accuracy_validation_nb)
print("Accuracy Score for test data:", accuracy_test_nb)
print("Accuracy Score for test data (fine-tuned):", accuracy_test_nb_fine_tuned)

"""# Naive Bayes Classifier with TF-IDF Vectorizer with Stopwords"""

# Build the model
model = make_pipeline(TfidfVectorizer(stop_words=stopWords), MultinomialNB())

# Fit the Train Data
model.fit(X_train, y_train)

print("\n*** Validation Data Starts ***\n")

# Predict the Validation Data
predictions = model.predict(X_valid)

# Accuracy of the Naive Bayes for validation
accuracy_validation_nb = accuracy_score(y_valid, predictions)

print("Classification Report for Naive Bayesian (Validation):")
print(classification_report(y_valid, predictions))

# Accuracy of the Naive Bayes for test
print("\n*** Test Data Starts ***\n")
model.fit(data_text, data_label)

predictions = model.predict(test_data_text)

accuracy_test_nb = accuracy_score(test_data_label, predictions)

print("Classification Report for Naive Bayesian (Test):")
print(classification_report(test_data_label, predictions))

# Accuract with Fine-Tuning (GridSearchCV)
print("\n*** GridSearchCV Starts ***\n")
vectorizer = TfidfVectorizer()
vec_x = vectorizer.fit_transform(data_text)

grid = GridSearchCV(MultinomialNB(), param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001]}, scoring="accuracy")
grid.fit(vec_x, data_label)

print("Best estimators:", grid.best_estimator_)
print("Best params:", grid.best_params_)
print("Validation Score (Fine-Tuning):", grid.best_score_)

# Fine-Tuned NaiveBayes
best_alpha = grid.best_params_["alpha"]
print("\n*** Test Data Starts with Fine-Tune ***\n")
model = make_pipeline(TfidfVectorizer(), MultinomialNB(alpha=best_alpha))

model.fit(data_text, data_label)
predictions = model.predict(test_data_text)

accuracy_test_nb_fine_tuned = accuracy_score(test_data_label, predictions)

print("Classification Report for Naive Bayesian Fine-Tuned (Test):")
print(classification_report(test_data_label, predictions))


print("\n\n*** Accuracy Results ***")
print("Accuracy Score for validation data:", accuracy_validation_nb)
print("Accuracy Score for test data:", accuracy_test_nb)
print("Accuracy Score for test data (fine-tuned):", accuracy_test_nb_fine_tuned)

"""# Naive Bayes Classifier with TF Vectorizer NO Stopwords"""

# Build the model
model = make_pipeline(CountVectorizer(), MultinomialNB())

# Fit the Train Data
model.fit(X_train, y_train)

print("\n*** Validation Data Starts ***\n")

# Predict the Validation Data
predictions = model.predict(X_valid)

# Accuracy of the Naive Bayes for validation
accuracy_validation_nb = accuracy_score(y_valid, predictions)

print("Classification Report for Naive Bayesian (Validation):")
print(classification_report(y_valid, predictions))

# Accuracy of the Naive Bayes for test
print("\n*** Test Data Starts ***\n")
model.fit(data_text, data_label)

predictions = model.predict(test_data_text)

accuracy_test_nb = accuracy_score(test_data_label, predictions)

print("Classification Report for Naive Bayesian (Test):")
print(classification_report(test_data_label, predictions))

# Accuract with Fine-Tuning (GridSearchCV)
print("\n*** GridSearchCV Starts ***\n")
vectorizer = TfidfVectorizer()
vec_x = vectorizer.fit_transform(data_text)

grid = GridSearchCV(MultinomialNB(), param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001]}, scoring="accuracy")
grid.fit(vec_x, data_label)

print("Best estimators:", grid.best_estimator_)
print("Best params:", grid.best_params_)
print("Validation Score (Fine-Tuning):", grid.best_score_)

# Fine-Tuned NaiveBayes
best_alpha = grid.best_params_["alpha"]
print("\n*** Test Data Starts with Fine-Tune ***\n")
model = make_pipeline(TfidfVectorizer(), MultinomialNB(alpha=best_alpha))

model.fit(data_text, data_label)
predictions = model.predict(test_data_text)

accuracy_test_nb_fine_tuned = accuracy_score(test_data_label, predictions)

print("Classification Report for Naive Bayesian Fine-Tuned (Test):")
print(classification_report(test_data_label, predictions))


print("\n\n*** Accuracy Results ***")
print("Accuracy Score for validation data:", accuracy_validation_nb)
print("Accuracy Score for test data:", accuracy_test_nb)
print("Accuracy Score for test data (fine-tuned):", accuracy_test_nb_fine_tuned)

"""# Naive Bayes Classifier with TF Vectorizer with Stopwords

"""

# Build the model
model = make_pipeline(CountVectorizer(stop_words=stopWords), MultinomialNB())

# Fit the Train Data
model.fit(X_train, y_train)

print("\n*** Validation Data Starts ***\n")

# Predict the Validation Data
predictions = model.predict(X_valid)

# Accuracy of the Naive Bayes for validation
accuracy_validation_nb = accuracy_score(y_valid, predictions)

print("Classification Report for Naive Bayesian (Validation):")
print(classification_report(y_valid, predictions))

# Accuracy of the Naive Bayes for test
print("\n*** Test Data Starts ***\n")
model.fit(data_text, data_label)

predictions = model.predict(test_data_text)

accuracy_test_nb = accuracy_score(test_data_label, predictions)

print("Classification Report for Naive Bayesian (Test):")
print(classification_report(test_data_label, predictions))

# Accuract with Fine-Tuning (GridSearchCV)
print("\n*** GridSearchCV Starts ***\n")
vectorizer = TfidfVectorizer()
vec_x = vectorizer.fit_transform(data_text)

grid = GridSearchCV(MultinomialNB(), param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001]}, scoring="accuracy")
grid.fit(vec_x, data_label)

print("Best estimators:", grid.best_estimator_)
print("Best params:", grid.best_params_)
print("Validation Score (Fine-Tuning):", grid.best_score_)

# Fine-Tuned NaiveBayes
best_alpha = grid.best_params_["alpha"]
print("\n*** Test Data Starts with Fine-Tune ***\n")
model = make_pipeline(TfidfVectorizer(), MultinomialNB(alpha=best_alpha))

model.fit(data_text, data_label)
predictions = model.predict(test_data_text)

accuracy_test_nb_fine_tuned = accuracy_score(test_data_label, predictions)

print("Classification Report for Naive Bayesian Fine-Tuned (Test):")
print(classification_report(test_data_label, predictions))


print("\n\n*** Accuracy Results ***")
print("Accuracy Score for validation data:", accuracy_validation_nb)
print("Accuracy Score for test data:", accuracy_test_nb)
print("Accuracy Score for test data (fine-tuned):", accuracy_test_nb_fine_tuned)

"""# Logistic Regression Classifier TF-IDF NO Stopwords


"""

# Build the model
model = make_pipeline(TfidfVectorizer(), LogisticRegression())

# Fit the Train Data
model.fit(X_train, y_train)

print("\n*** Validation Data Starts ***\n")

# Predict the Validation Data
predictions = model.predict(X_valid)

# Accuracy of the Logistic Regression for validation
accuracy_validation_logres = accuracy_score(y_valid, predictions)

print("Classification Report for Logistic Regression (Validation):")
print(classification_report(y_valid, predictions))

# Accuracy of the Logistic Regression for test
print("\n*** Test Data Starts ***\n")
model.fit(data_text, data_label)

predictions = model.predict(test_data_text)

accuracy_test_logres = accuracy_score(test_data_label, predictions)

print("Classification Report for Logistic Regression (Test):")
print(classification_report(test_data_label, predictions))

# # Accuract with Fine-Tuning (GridSearchCV)
# print("\n*** GridSearchCV Starts ***\n")
# vectorizer = TfidfVectorizer()
# vec_x = vectorizer.fit_transform(data_text)

# # solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}
# # c_values = [100, 10, 1.0, 0.1, 0.01]

# parameters = {
#     "solver": ["newton-cg", "lbfgs", "liblinear", "sag", "saga"],
#     "C": [100, 10, 1.0, 0.1, 0.01],
# }

# grid = GridSearchCV(LogisticRegression(max_iter=200), param_grid=parameters, scoring="accuracy")
# grid.fit(vec_x, data_label)

# print("Best estimators:", grid.best_estimator_)
# print("Best params:", grid.best_params_)
# print("Validation Score (Fine-Tuning):", grid.best_score_)

"""# Logistic Regression Classifier TF-IDF with Stopwords"""

# Build the model
model = make_pipeline(TfidfVectorizer(stop_words=stopWords), LogisticRegression(max_iter=200))

# Fit the Train Data
model.fit(X_train, y_train)

print("\n*** Validation Data Starts ***\n")

# Predict the Validation Data
predictions = model.predict(X_valid)

# Accuracy of the Logistic Regression for validation
accuracy_validation_logres = accuracy_score(y_valid, predictions)

print("Classification Report for Logistic Regression (Validation):")
print(classification_report(y_valid, predictions))

# Accuracy of the Logistic Regression for test
print("\n*** Test Data Starts ***\n")
model.fit(data_text, data_label)

predictions = model.predict(test_data_text)

accuracy_test_logres = accuracy_score(test_data_label, predictions)

print("Classification Report for Logistic Regression (Test):")
print(classification_report(test_data_label, predictions))

# # Accuract with Fine-Tuning (GridSearchCV)
# print("\n*** GridSearchCV Starts ***\n")
# vectorizer = TfidfVectorizer()
# vec_x = vectorizer.fit_transform(data_text)

# # solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}
# # c_values = [100, 10, 1.0, 0.1, 0.01]

# parameters = {
#     "solver": ["newton-cg", "lbfgs", "liblinear", "sag", "saga"],
#     "C": [100, 10, 1.0, 0.1, 0.01],
# }

# grid = GridSearchCV(LogisticRegression(max_iter=200), param_grid=parameters, scoring="accuracy")
# grid.fit(vec_x, data_label)

# print("Best estimators:", grid.best_estimator_)
# print("Best params:", grid.best_params_)
# print("Validation Score (Fine-Tuning):", grid.best_score_)

"""# Logistic Regression Classifier TF NO Stopword"""

# Build the model
model = make_pipeline(CountVectorizer(), LogisticRegression(max_iter=400))

# Fit the Train Data
model.fit(X_train, y_train)

print("\n*** Validation Data Starts ***\n")

# Predict the Validation Data
predictions = model.predict(X_valid)

# Accuracy of the Logistic Regression for validation
accuracy_validation_logres = accuracy_score(y_valid, predictions)

print("Classification Report for Logistic Regression (Validation):")
print(classification_report(y_valid, predictions))

# Accuracy of the Logistic Regression for test
print("\n*** Test Data Starts ***\n")
model.fit(data_text, data_label)

predictions = model.predict(test_data_text)

accuracy_test_logres = accuracy_score(test_data_label, predictions)

print("Classification Report for Logistic Regression (Test):")
print(classification_report(test_data_label, predictions))

# # Accuract with Fine-Tuning (GridSearchCV)
# print("\n*** GridSearchCV Starts ***\n")
# vectorizer = TfidfVectorizer()
# vec_x = vectorizer.fit_transform(data_text)

# # solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}
# # c_values = [100, 10, 1.0, 0.1, 0.01]

# parameters = {
#     "solver": ["newton-cg", "lbfgs", "liblinear", "sag", "saga"],
#     "C": [100, 10, 1.0, 0.1, 0.01],
# }

# grid = GridSearchCV(LogisticRegression(max_iter=200), param_grid=parameters, scoring="accuracy")
# grid.fit(vec_x, data_label)

# print("Best estimators:", grid.best_estimator_)
# print("Best params:", grid.best_params_)
# print("Validation Score (Fine-Tuning):", grid.best_score_)

"""# Logistic Regression Classifier TF With Stopwords"""

# Build the model
model = make_pipeline(CountVectorizer(stop_words=stopWords), LogisticRegression(max_iter=1000))

# Fit the Train Data
model.fit(X_train, y_train)

print("\n*** Validation Data Starts ***\n")

# Predict the Validation Data
predictions = model.predict(X_valid)

# Accuracy of the Logistic Regression for validation
accuracy_validation_logres = accuracy_score(y_valid, predictions)

print("Classification Report for Logistic Regression (Validation):")
print(classification_report(y_valid, predictions))

# Accuracy of the Logistic Regression for test
print("\n*** Test Data Starts ***\n")
model.fit(data_text, data_label)

predictions = model.predict(test_data_text)

accuracy_test_logres = accuracy_score(test_data_label, predictions)

print("Classification Report for Logistic Regression (Test):")
print(classification_report(test_data_label, predictions))

# Accuract with Fine-Tuning (GridSearchCV)
print("\n*** GridSearchCV Starts ***\n")
vectorizer = CountVectorizer()
vec_x = vectorizer.fit_transform(data_text)

# solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}
# c_values = [100, 10, 1.0, 0.1, 0.01]

parameters = {
    "C": [100, 10, 1.0, 0.1, 0.01],
}

grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid=parameters, scoring="accuracy")
grid.fit(vec_x, data_label)

print("Best estimators:", grid.best_estimator_)
print("Best params:", grid.best_params_)
print("Validation Score (Fine-Tuning):", grid.best_score_)

# Build the model
model = make_pipeline(CountVectorizer(stop_words=stopWords), LogisticRegression(max_iter=1000, C=0.1))

# Fit the Train Data
model.fit(X_train, y_train)

print("\n*** Validation Data Starts ***\n")

# Predict the Validation Data
predictions = model.predict(X_valid)

# Accuracy of the Logistic Regression for validation
accuracy_validation_logres = accuracy_score(y_valid, predictions)

print("Classification Report for Logistic Regression (Validation):")
print(classification_report(y_valid, predictions))

# Accuracy of the Logistic Regression for test
print("\n*** Test Data Starts ***\n")
model.fit(data_text, data_label)

predictions = model.predict(test_data_text)

accuracy_test_logres = accuracy_score(test_data_label, predictions)

print("Classification Report for Logistic Regression (Test):")
print(classification_report(test_data_label, predictions))

"""# Logistic Regression"""

# Build the model
model = make_pipeline(TfidfVectorizer(), LogisticRegression())

model.fit(X_train, y_train)

predictions = model.predict(X_test)

accuracy_score(y_test, predictions)

print("Classification Report for Logistic Regression:")
print(classification_report(y_test, predictions))

predictions = model.predict(test_data_text)

accuracy_score(test_data_label, predictions)

print("Classification Report for Logistic Regression:")
print(classification_report(test_data_label, predictions))

"""# GridSearch for Logistic Regression"""

vectorizer = TfidfVectorizer()
vec_x = vectorizer.fit_transform(X_train)

params = {
    "solver": ["newton-cg", "lbfgs", "liblinear", "sag", "saga"],
    "C": np.logspace(-3,3,7),
}

# solver{‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’}, default=’lbfgs’


grid = GridSearchCV(LogisticRegression(), param_grid=params, scoring="accuracy")
grid.fit(vec_x, y_train)
print(grid)

grid.best_estimator_

grid.best_params_

grid.best_score_

"""# Naive Bayes"""

# Build the model
model = make_pipeline(TfidfVectorizer(), MultinomialNB())

model.fit(X_train, y_train)

predictions = model.predict(X_test)

accuracy_score(y_test, predictions)

print("Classification Report for Naive Bayesian:")
print(classification_report(y_test, predictions))

predictions = model.predict(test_data_text)

accuracy_score(test_data_label, predictions)

print("Classification Report for Naive Bayesian:")
print(classification_report(test_data_label, predictions))

"""# GridSearch for Naive Bayes"""

vectorizer = TfidfVectorizer()
vec_x = vectorizer.fit_transform(X_train)

grid = GridSearchCV(MultinomialNB(), param_grid={'alpha': [1.0, 0.1, 0.01, 0.001, 0.0001]}, scoring="accuracy")
grid.fit(vec_x, y_train)
print(grid)

grid.best_estimator_

grid.best_params_

grid.best_score_

# Build the model
model = make_pipeline(TfidfVectorizer(), MultinomialNB(alpha=0.01))

model.fit(data_text, data_label)
predictions = model.predict(test_data_text)

print("Classification Report for Naive Bayesian:")
print(classification_report(test_data_label, predictions))